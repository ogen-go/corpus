{
	"File": {
		"__typename": "FileMatch",
		"repository": {
			"name": "github.com/restful-ma/thresholds"
		},
		"file": {
			"name": "amazonaws.com-firehose-2015-08-04-swagger.yaml",
			"size": 0,
			"path": "benchmark-repository/openapi/amazonaws.com-firehose-2015-08-04-swagger.yaml",
			"byteSize": 90380,
			"content": "openapi: 3.0.0\ninfo:\n  version: 2015-08-04\n  x-release: v4\n  title: Amazon Kinesis Firehose\n  description: \u003cfullname\u003eAmazon Kinesis Data Firehose API Reference\u003c/fullname\u003e \u003cp\u003eAmazon\n    Kinesis Data Firehose is a fully managed service that delivers real-time\n    streaming data to destinations such as Amazon Simple Storage Service (Amazon\n    S3), Amazon Elasticsearch Service (Amazon ES), Amazon Redshift, and\n    Splunk.\u003c/p\u003e\n  x-logo:\n    url: https://twitter.com/awscloud/profile_image?size=original\n    backgroundColor: \"#FFFFFF\"\n  termsOfService: https://aws.amazon.com/service-terms/\n  contact:\n    name: Mike Ralphson\n    email: mike.ralphson@gmail.com\n    url: https://github.com/mermade/aws2openapi\n    x-twitter: PermittedSoc\n  license:\n    name: Apache 2.0 License\n    url: http://www.apache.org/licenses/\n  x-providerName: amazonaws.com\n  x-serviceName: firehose\n  x-origin:\n    - contentType: application/json\n      url: https://raw.githubusercontent.com/aws/aws-sdk-js/master/apis/firehose-2015-08-04.normal.json\n      converter:\n        url: https://github.com/mermade/aws2openapi\n        version: 1.0.0\n      x-apisguru-direct: true\n  x-apiClientRegistration:\n    url: https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct\n  x-apisguru-categories:\n    - cloud\n  x-preferred: true\nexternalDocs:\n  description: Amazon Web Services documentation\n  url: https://docs.aws.amazon.com/firehose/\nx-hasEquivalentPaths: true\nsecurity:\n  - hmac: []\npaths:\n  /#X-Amz-Target=Firehose_20150804.CreateDeliveryStream:\n    post:\n      operationId: CreateDeliveryStream\n      description: \"\u003cp\u003eCreates a Kinesis Data Firehose delivery stream.\u003c/p\u003e \u003cp\u003eBy default,\n        you can create up to 50 delivery streams per AWS Region.\u003c/p\u003e \u003cp\u003eThis is\n        an asynchronous operation that immediately returns. The initial status\n        of the delivery stream is \u003ccode\u003eCREATING\u003c/code\u003e. After the delivery\n        stream is created, its status is \u003ccode\u003eACTIVE\u003c/code\u003e and it now accepts\n        data. Attempts to send data to a delivery stream that is not in the\n        \u003ccode\u003eACTIVE\u003c/code\u003e state cause an exception. To check the state of a\n        delivery stream, use \u003ca\u003eDescribeDeliveryStream\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eA Kinesis\n        Data Firehose delivery stream can be configured to receive records\n        directly from providers using \u003ca\u003ePutRecord\u003c/a\u003e or \u003ca\u003ePutRecordBatch\u003c/a\u003e,\n        or it can be configured to use an existing Kinesis stream as its source.\n        To specify a Kinesis data stream as input, set the\n        \u003ccode\u003eDeliveryStreamType\u003c/code\u003e parameter to\n        \u003ccode\u003eKinesisStreamAsSource\u003c/code\u003e, and provide the Kinesis stream\n        Amazon Resource Name (ARN) and role ARN in the\n        \u003ccode\u003eKinesisStreamSourceConfiguration\u003c/code\u003e parameter.\u003c/p\u003e \u003cp\u003eA\n        delivery stream is configured with a single destination: Amazon S3,\n        Amazon ES, Amazon Redshift, or Splunk. You must specify only one of the\n        following destination configuration parameters:\n        \u003ccode\u003eExtendedS3DestinationConfiguration\u003c/code\u003e,\n        \u003ccode\u003eS3DestinationConfiguration\u003c/code\u003e,\n        \u003ccode\u003eElasticsearchDestinationConfiguration\u003c/code\u003e,\n        \u003ccode\u003eRedshiftDestinationConfiguration\u003c/code\u003e, or\n        \u003ccode\u003eSplunkDestinationConfiguration\u003c/code\u003e.\u003c/p\u003e \u003cp\u003eWhen you specify\n        \u003ccode\u003eS3DestinationConfiguration\u003c/code\u003e, you can also provide the\n        following optional values: BufferingHints,\n        \u003ccode\u003eEncryptionConfiguration\u003c/code\u003e, and\n        \u003ccode\u003eCompressionFormat\u003c/code\u003e. By default, if no\n        \u003ccode\u003eBufferingHints\u003c/code\u003e value is provided, Kinesis Data Firehose\n        buffers data up to 5 MB or for 5 minutes, whichever condition is\n        satisfied first. \u003ccode\u003eBufferingHints\u003c/code\u003e is a hint, so there are\n        some cases where the service cannot adhere to these conditions strictly.\n        For example, record boundaries might be such that the size is a little\n        over or under the configured buffering size. By default, no encryption\n        is performed. We strongly recommend that you enable encryption to ensure\n        secure data storage in Amazon S3.\u003c/p\u003e \u003cp\u003eA few notes about Amazon\n        Redshift as a destination:\u003c/p\u003e \u003cul\u003e \u003cli\u003e \u003cp\u003eAn Amazon Redshift\n        destination requires an S3 bucket as intermediate location. Kinesis Data\n        Firehose first delivers data to Amazon S3 and then uses\n        \u003ccode\u003eCOPY\u003c/code\u003e syntax to load data into an Amazon Redshift table.\n        This is specified in the\n        \u003ccode\u003eRedshiftDestinationConfiguration.S3Configuration\u003c/code\u003e\n        parameter.\u003c/p\u003e \u003c/li\u003e \u003cli\u003e \u003cp\u003eThe compression formats \u003ccode\u003eSNAPPY\u003c/code\u003e\n        or \u003ccode\u003eZIP\u003c/code\u003e cannot be specified in\n        \u003ccode\u003eRedshiftDestinationConfiguration.S3Configuration\u003c/code\u003e because\n        the Amazon Redshift \u003ccode\u003eCOPY\u003c/code\u003e operation that reads from the S3\n        bucket doesn't support these compression formats.\u003c/p\u003e \u003c/li\u003e \u003cli\u003e \u003cp\u003eWe\n        strongly recommend that you use the user name and password you provide\n        exclusively with Kinesis Data Firehose, and that the permissions for the\n        account are restricted for Amazon Redshift \u003ccode\u003eINSERT\u003c/code\u003e\n        permissions.\u003c/p\u003e \u003c/li\u003e \u003c/ul\u003e \u003cp\u003eKinesis Data Firehose assumes the IAM\n        role that is configured as part of the destination. The role should\n        allow the Kinesis Data Firehose principal to assume the role, and the\n        role should have permissions that allow the service to deliver the data.\n        For more information, see \u003ca\n        href=\\\"http://docs.aws.amazon.com/firehose/latest/dev/controlling-acces\\\n        s.html#using-iam-s3\\\"\u003eGrant Kinesis Data Firehose Access to an Amazon S3\n        Destination\u003c/a\u003e in the \u003ci\u003eAmazon Kinesis Data Firehose Developer\n        Guide\u003c/i\u003e.\u003c/p\u003e\"\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/CreateDeliveryStreamOutput\"\n        \"480\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"481\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n        \"482\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.CreateDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/CreateDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.DeleteDeliveryStream:\n    post:\n      operationId: DeleteDeliveryStream\n      description: \u003cp\u003eDeletes a delivery stream and its data.\u003c/p\u003e \u003cp\u003eYou can delete a\n        delivery stream only if it is in \u003ccode\u003eACTIVE\u003c/code\u003e or\n        \u003ccode\u003eDELETING\u003c/code\u003e state, and not in the \u003ccode\u003eCREATING\u003c/code\u003e state.\n        While the deletion request is in process, the delivery stream is in the\n        \u003ccode\u003eDELETING\u003c/code\u003e state.\u003c/p\u003e \u003cp\u003eTo check the state of a delivery\n        stream, use \u003ca\u003eDescribeDeliveryStream\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eWhile the delivery\n        stream is \u003ccode\u003eDELETING\u003c/code\u003e state, the service might continue to\n        accept the records, but it doesn't make any guarantees with respect to\n        delivering the data. Therefore, as a best practice, you should first\n        stop any applications that are sending records before deleting a\n        delivery stream.\u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeleteDeliveryStreamOutput\"\n        \"480\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"481\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.DeleteDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/DeleteDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.DescribeDeliveryStream:\n    post:\n      operationId: DescribeDeliveryStream\n      description: Describes the specified delivery stream and gets the status. For\n        example, after your delivery stream is created, call\n        \u003ccode\u003eDescribeDeliveryStream\u003c/code\u003e to see whether the delivery stream\n        is \u003ccode\u003eACTIVE\u003c/code\u003e and therefore ready for data to be sent to it.\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DescribeDeliveryStreamOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.DescribeDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/DescribeDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.ListDeliveryStreams:\n    post:\n      operationId: ListDeliveryStreams\n      description: \u003cp\u003eLists your delivery streams in alphabetical order of their names.\u003c/p\u003e\n        \u003cp\u003eThe number of delivery streams might be too large to return using a\n        single call to \u003ccode\u003eListDeliveryStreams\u003c/code\u003e. You can limit the\n        number of delivery streams returned, using the \u003ccode\u003eLimit\u003c/code\u003e\n        parameter. To determine whether there are more delivery streams to list,\n        check the value of \u003ccode\u003eHasMoreDeliveryStreams\u003c/code\u003e in the output. If\n        there are more delivery streams to list, you can request them by calling\n        this operation again and setting the\n        \u003ccode\u003eExclusiveStartDeliveryStreamName\u003c/code\u003e parameter to the name of\n        the last delivery stream returned in the last call.\u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ListDeliveryStreamsOutput\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.ListDeliveryStreams\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/ListDeliveryStreamsInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.ListTagsForDeliveryStream:\n    post:\n      operationId: ListTagsForDeliveryStream\n      description: \"Lists the tags for the specified delivery stream. This operation has a\n        limit of five transactions per second per account. \"\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ListTagsForDeliveryStreamOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"482\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.ListTagsForDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/ListTagsForDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.PutRecord:\n    post:\n      operationId: PutRecord\n      description: \u003cp\u003eWrites a single data record into an Amazon Kinesis Data Firehose\n        delivery stream. To write multiple data records into a delivery stream,\n        use \u003ca\u003ePutRecordBatch\u003c/a\u003e. Applications using these operations are\n        referred to as producers.\u003c/p\u003e \u003cp\u003eBy default, each delivery stream can\n        take in up to 2,000 transactions per second, 5,000 records per second,\n        or 5 MB per second. If you use \u003ca\u003ePutRecord\u003c/a\u003e and\n        \u003ca\u003ePutRecordBatch\u003c/a\u003e, the limits are an aggregate across these two\n        operations for each delivery stream. For more information about limits\n        and how to request an increase, see \u003ca\n        href=\"http://docs.aws.amazon.com/firehose/latest/dev/limits.html\"\u003eAmazon\n        Kinesis Data Firehose Limits\u003c/a\u003e. \u003c/p\u003e \u003cp\u003eYou must specify the name of\n        the delivery stream and the data record when using \u003ca\u003ePutRecord\u003c/a\u003e. The\n        data record consists of a data blob that can be up to 1,000 KB in size,\n        and any kind of data. For example, it can be a segment from a log file,\n        geographic location data, website clickstream data, and so on.\u003c/p\u003e\n        \u003cp\u003eKinesis Data Firehose buffers records before delivering them to the\n        destination. To disambiguate the data blobs at the destination, a common\n        solution is to use delimiters in the data, such as a newline\n        (\u003ccode\u003e\\n\u003c/code\u003e) or some other character unique within the data. This\n        allows the consumer application to parse individual data items when\n        reading the data from the destination.\u003c/p\u003e \u003cp\u003eThe \u003ccode\u003ePutRecord\u003c/code\u003e\n        operation returns a \u003ccode\u003eRecordId\u003c/code\u003e, which is a unique string\n        assigned to each record. Producer applications can use this ID for\n        purposes such as auditability and investigation.\u003c/p\u003e \u003cp\u003eIf the\n        \u003ccode\u003ePutRecord\u003c/code\u003e operation throws a\n        \u003ccode\u003eServiceUnavailableException\u003c/code\u003e, back off and retry. If the\n        exception persists, it is possible that the throughput limits have been\n        exceeded for the delivery stream. \u003c/p\u003e \u003cp\u003eData records sent to Kinesis\n        Data Firehose are stored for 24 hours from the time they are added to a\n        delivery stream as it tries to send the records to the destination. If\n        the destination is unreachable for more than 24 hours, the data is no\n        longer available.\u003c/p\u003e \u003cimportant\u003e \u003cp\u003eDon't concatenate two or more\n        base64 strings to form the data fields of your records. Instead,\n        concatenate the raw data, then perform base64 encoding.\u003c/p\u003e \u003c/important\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/PutRecordOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"482\":\n          description: ServiceUnavailableException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ServiceUnavailableException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.PutRecord\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/PutRecordInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.PutRecordBatch:\n    post:\n      operationId: PutRecordBatch\n      description: \"\u003cp\u003eWrites multiple data records into a delivery stream in a single\n        call, which can achieve higher throughput per producer than when writing\n        single records. To write single data records into a delivery stream, use\n        \u003ca\u003ePutRecord\u003c/a\u003e. Applications using these operations are referred to as\n        producers.\u003c/p\u003e \u003cp\u003eBy default, each delivery stream can take in up to\n        2,000 transactions per second, 5,000 records per second, or 5 MB per\n        second. If you use \u003ca\u003ePutRecord\u003c/a\u003e and \u003ca\u003ePutRecordBatch\u003c/a\u003e, the\n        limits are an aggregate across these two operations for each delivery\n        stream. For more information about limits, see \u003ca\n        href=\\\"http://docs.aws.amazon.com/firehose/latest/dev/limits.html\\\"\u003eAma\\\n        zon Kinesis Data Firehose Limits\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eEach \u003ca\u003ePutRecordBatch\u003c/a\u003e\n        request supports up to 500 records. Each record in the request can be as\n        large as 1,000 KB (before 64-bit encoding), up to a limit of 4 MB for\n        the entire request. These limits cannot be changed.\u003c/p\u003e \u003cp\u003eYou must\n        specify the name of the delivery stream and the data record when using\n        \u003ca\u003ePutRecord\u003c/a\u003e. The data record consists of a data blob that can be up\n        to 1,000 KB in size, and any kind of data. For example, it could be a\n        segment from a log file, geographic location data, website clickstream\n        data, and so on.\u003c/p\u003e \u003cp\u003eKinesis Data Firehose buffers records before\n        delivering them to the destination. To disambiguate the data blobs at\n        the destination, a common solution is to use delimiters in the data,\n        such as a newline (\u003ccode\u003e\\\\n\u003c/code\u003e) or some other character unique\n        within the data. This allows the consumer application to parse\n        individual data items when reading the data from the destination.\u003c/p\u003e\n        \u003cp\u003eThe \u003ca\u003ePutRecordBatch\u003c/a\u003e response includes a count of failed\n        records, \u003ccode\u003eFailedPutCount\u003c/code\u003e, and an array of responses,\n        \u003ccode\u003eRequestResponses\u003c/code\u003e. Even if the \u003ca\u003ePutRecordBatch\u003c/a\u003e call\n        succeeds, the value of \u003ccode\u003eFailedPutCount\u003c/code\u003e may be greater than\n        0, indicating that there are records for which the operation didn't\n        succeed. Each entry in the \u003ccode\u003eRequestResponses\u003c/code\u003e array provides\n        additional information about the processed record. It directly\n        correlates with a record in the request array using the same ordering,\n        from the top to the bottom. The response array always includes the same\n        number of records as the request array. \u003ccode\u003eRequestResponses\u003c/code\u003e\n        includes both successfully and unsuccessfully processed records. Kinesis\n        Data Firehose tries to process all records in each \u003ca\u003ePutRecordBatch\u003c/a\u003e\n        request. A single record failure does not stop the processing of\n        subsequent records. \u003c/p\u003e \u003cp\u003eA successfully processed record includes a\n        \u003ccode\u003eRecordId\u003c/code\u003e value, which is unique for the record. An\n        unsuccessfully processed record includes \u003ccode\u003eErrorCode\u003c/code\u003e and\n        \u003ccode\u003eErrorMessage\u003c/code\u003e values. \u003ccode\u003eErrorCode\u003c/code\u003e reflects the\n        type of error, and is one of the following values:\n        \u003ccode\u003eServiceUnavailableException\u003c/code\u003e or\n        \u003ccode\u003eInternalFailure\u003c/code\u003e. \u003ccode\u003eErrorMessage\u003c/code\u003e provides more\n        detailed information about the error.\u003c/p\u003e \u003cp\u003eIf there is an internal\n        server error or a timeout, the write might have completed or it might\n        have failed. If \u003ccode\u003eFailedPutCount\u003c/code\u003e is greater than 0, retry the\n        request, resending only those records that might have failed processing.\n        This minimizes the possible duplicate records and also reduces the total\n        bytes sent (and corresponding charges). We recommend that you handle any\n        duplicates at the destination.\u003c/p\u003e \u003cp\u003eIf \u003ca\u003ePutRecordBatch\u003c/a\u003e throws\n        \u003ccode\u003eServiceUnavailableException\u003c/code\u003e, back off and retry. If the\n        exception persists, it is possible that the throughput limits have been\n        exceeded for the delivery stream.\u003c/p\u003e \u003cp\u003eData records sent to Kinesis\n        Data Firehose are stored for 24 hours from the time they are added to a\n        delivery stream as it attempts to send the records to the destination.\n        If the destination is unreachable for more than 24 hours, the data is no\n        longer available.\u003c/p\u003e \u003cimportant\u003e \u003cp\u003eDon't concatenate two or more\n        base64 strings to form the data fields of your records. Instead,\n        concatenate the raw data, then perform base64 encoding.\u003c/p\u003e\n        \u003c/important\u003e\"\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/PutRecordBatchOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"482\":\n          description: ServiceUnavailableException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ServiceUnavailableException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.PutRecordBatch\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/PutRecordBatchInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.StartDeliveryStreamEncryption:\n    post:\n      operationId: StartDeliveryStreamEncryption\n      description: \u003cp\u003eEnables server-side encryption (SSE) for the delivery stream. \u003c/p\u003e\n        \u003cp\u003eThis operation is asynchronous. It returns immediately. When you\n        invoke it, Kinesis Data Firehose first sets the status of the stream to\n        \u003ccode\u003eENABLING\u003c/code\u003e, and then to \u003ccode\u003eENABLED\u003c/code\u003e. You can\n        continue to read and write data to your stream while its status is\n        \u003ccode\u003eENABLING\u003c/code\u003e, but the data is not encrypted. It can take up to\n        5 seconds after the encryption status changes to \u003ccode\u003eENABLED\u003c/code\u003e\n        before all records written to the delivery stream are encrypted. To find\n        out whether a record or a batch of records was encrypted, check the\n        response elements \u003ca\u003ePutRecordOutput$Encrypted\u003c/a\u003e and\n        \u003ca\u003ePutRecordBatchOutput$Encrypted\u003c/a\u003e, respectively.\u003c/p\u003e \u003cp\u003eTo check the\n        encryption state of a delivery stream, use\n        \u003ca\u003eDescribeDeliveryStream\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eYou can only enable SSE for a\n        delivery stream that uses \u003ccode\u003eDirectPut\u003c/code\u003e as its source. \u003c/p\u003e\n        \u003cp\u003eThe \u003ccode\u003eStartDeliveryStreamEncryption\u003c/code\u003e and\n        \u003ccode\u003eStopDeliveryStreamEncryption\u003c/code\u003e operations have a combined\n        limit of 25 calls per delivery stream per 24 hours. For example, you\n        reach the limit if you call \u003ccode\u003eStartDeliveryStreamEncryption\u003c/code\u003e\n        13 times and \u003ccode\u003eStopDeliveryStreamEncryption\u003c/code\u003e 12 times for the\n        same delivery stream in a 24-hour period.\u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/StartDeliveryStreamEncryptionOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"482\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"483\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.StartDeliveryStreamEncryption\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/StartDeliveryStreamEncryptionInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.StopDeliveryStreamEncryption:\n    post:\n      operationId: StopDeliveryStreamEncryption\n      description: \u003cp\u003eDisables server-side encryption (SSE) for the delivery stream. \u003c/p\u003e\n        \u003cp\u003eThis operation is asynchronous. It returns immediately. When you\n        invoke it, Kinesis Data Firehose first sets the status of the stream to\n        \u003ccode\u003eDISABLING\u003c/code\u003e, and then to \u003ccode\u003eDISABLED\u003c/code\u003e. You can\n        continue to read and write data to your stream while its status is\n        \u003ccode\u003eDISABLING\u003c/code\u003e. It can take up to 5 seconds after the encryption\n        status changes to \u003ccode\u003eDISABLED\u003c/code\u003e before all records written to\n        the delivery stream are no longer subject to encryption. To find out\n        whether a record or a batch of records was encrypted, check the response\n        elements \u003ca\u003ePutRecordOutput$Encrypted\u003c/a\u003e and\n        \u003ca\u003ePutRecordBatchOutput$Encrypted\u003c/a\u003e, respectively.\u003c/p\u003e \u003cp\u003eTo check the\n        encryption state of a delivery stream, use\n        \u003ca\u003eDescribeDeliveryStream\u003c/a\u003e. \u003c/p\u003e \u003cp\u003eThe\n        \u003ccode\u003eStartDeliveryStreamEncryption\u003c/code\u003e and\n        \u003ccode\u003eStopDeliveryStreamEncryption\u003c/code\u003e operations have a combined\n        limit of 25 calls per delivery stream per 24 hours. For example, you\n        reach the limit if you call \u003ccode\u003eStartDeliveryStreamEncryption\u003c/code\u003e\n        13 times and \u003ccode\u003eStopDeliveryStreamEncryption\u003c/code\u003e 12 times for the\n        same delivery stream in a 24-hour period.\u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/StopDeliveryStreamEncryptionOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"482\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"483\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.StopDeliveryStreamEncryption\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/StopDeliveryStreamEncryptionInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.TagDeliveryStream:\n    post:\n      operationId: TagDeliveryStream\n      description: \u003cp\u003eAdds or updates tags for the specified delivery stream. A tag is a\n        key-value pair that you can define and assign to AWS resources. If you\n        specify a tag that already exists, the tag value is replaced with the\n        value that you specify in the request. Tags are metadata. For example,\n        you can add friendly names and descriptions or other types of\n        information that can help you distinguish the delivery stream. For more\n        information about tags, see \u003ca\n        href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\"\u003eUsing\n        Cost Allocation Tags\u003c/a\u003e in the \u003ci\u003eAWS Billing and Cost Management User\n        Guide\u003c/i\u003e. \u003c/p\u003e \u003cp\u003eEach delivery stream can have up to 50 tags. \u003c/p\u003e\n        \u003cp\u003eThis operation has a limit of five transactions per second per\n        account. \u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TagDeliveryStreamOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"482\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"483\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.TagDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/TagDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.UntagDeliveryStream:\n    post:\n      operationId: UntagDeliveryStream\n      description: \u003cp\u003eRemoves tags from the specified delivery stream. Removed tags are\n        deleted, and you can't recover them after this operation successfully\n        completes.\u003c/p\u003e \u003cp\u003eIf you specify a tag that doesn't exist, the operation\n        ignores it.\u003c/p\u003e \u003cp\u003eThis operation has a limit of five transactions per\n        second per account. \u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/UntagDeliveryStreamOutput\"\n        \"480\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"481\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"482\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"483\":\n          description: LimitExceededException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LimitExceededException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.UntagDeliveryStream\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/UntagDeliveryStreamInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\n  /#X-Amz-Target=Firehose_20150804.UpdateDestination:\n    post:\n      operationId: UpdateDestination\n      description: \u003cp\u003eUpdates the specified destination of the specified delivery\n        stream.\u003c/p\u003e \u003cp\u003eUse this operation to change the destination type (for\n        example, to replace the Amazon S3 destination with Amazon Redshift) or\n        change the parameters associated with a destination (for example, to\n        change the bucket name of the Amazon S3 destination). The update might\n        not occur immediately. The target delivery stream remains active while\n        the configurations are updated, so data writes to the delivery stream\n        can continue during this process. The updated configurations are usually\n        effective within a few minutes.\u003c/p\u003e \u003cp\u003eSwitching between Amazon ES and\n        other services is not supported. For an Amazon ES destination, you can\n        only update to another Amazon ES destination.\u003c/p\u003e \u003cp\u003eIf the destination\n        type is the same, Kinesis Data Firehose merges the configuration\n        parameters specified with the destination configuration that already\n        exists on the delivery stream. If any of the parameters are not\n        specified in the call, the existing values are retained. For example, in\n        the Amazon S3 destination, if \u003ca\u003eEncryptionConfiguration\u003c/a\u003e is not\n        specified, then the existing \u003ccode\u003eEncryptionConfiguration\u003c/code\u003e is\n        maintained on the destination.\u003c/p\u003e \u003cp\u003eIf the destination type is not the\n        same, for example, changing the destination from Amazon S3 to Amazon\n        Redshift, Kinesis Data Firehose does not merge any parameters. In this\n        case, all parameters must be specified.\u003c/p\u003e \u003cp\u003eKinesis Data Firehose\n        uses \u003ccode\u003eCurrentDeliveryStreamVersionId\u003c/code\u003e to avoid race\n        conditions and conflicting merges. This is a required field, and the\n        service updates the configuration only if the existing configuration has\n        a version ID that matches. After the update is applied successfully, the\n        version ID is updated, and can be retrieved using\n        \u003ca\u003eDescribeDeliveryStream\u003c/a\u003e. Use the new version ID to set\n        \u003ccode\u003eCurrentDeliveryStreamVersionId\u003c/code\u003e in the next call.\u003c/p\u003e\n      responses:\n        \"200\":\n          description: Success\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/UpdateDestinationOutput\"\n        \"480\":\n          description: InvalidArgumentException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/InvalidArgumentException\"\n        \"481\":\n          description: ResourceInUseException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceInUseException\"\n        \"482\":\n          description: ResourceNotFoundException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ResourceNotFoundException\"\n        \"483\":\n          description: ConcurrentModificationException\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ConcurrentModificationException\"\n      parameters:\n        - name: X-Amz-Target\n          in: header\n          required: true\n          schema:\n            type: string\n            enum:\n              - Firehose_20150804.UpdateDestination\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/UpdateDestinationInput\"\n        required: true\n    parameters:\n      - $ref: \"#/components/parameters/X-Amz-Content-Sha256\"\n      - $ref: \"#/components/parameters/X-Amz-Date\"\n      - $ref: \"#/components/parameters/X-Amz-Algorithm\"\n      - $ref: \"#/components/parameters/X-Amz-Credential\"\n      - $ref: \"#/components/parameters/X-Amz-Security-Token\"\n      - $ref: \"#/components/parameters/X-Amz-Signature\"\n      - $ref: \"#/components/parameters/X-Amz-SignedHeaders\"\nservers:\n  - url: http://firehose.{region}.amazonaws.com\n    variables:\n      region:\n        description: The AWS region\n        enum:\n          - us-east-1\n          - us-east-2\n          - us-west-1\n          - us-west-2\n          - us-gov-west-1\n          - us-gov-east-1\n          - ca-central-1\n          - eu-north-1\n          - eu-west-1\n          - eu-west-2\n          - eu-west-3\n          - eu-central-1\n          - ap-northeast-1\n          - ap-northeast-2\n          - ap-northeast-3\n          - ap-southeast-1\n          - ap-southeast-2\n          - ap-south-1\n          - sa-east-1\n        default: us-east-1\n    description: The Firehose multi-region endpoint\n  - url: https://firehose.{region}.amazonaws.com\n    variables:\n      region:\n        description: The AWS region\n        enum:\n          - us-east-1\n          - us-east-2\n          - us-west-1\n          - us-west-2\n          - us-gov-west-1\n          - us-gov-east-1\n          - ca-central-1\n          - eu-north-1\n          - eu-west-1\n          - eu-west-2\n          - eu-west-3\n          - eu-central-1\n          - ap-northeast-1\n          - ap-northeast-2\n          - ap-northeast-3\n          - ap-southeast-1\n          - ap-southeast-2\n          - ap-south-1\n          - sa-east-1\n        default: us-east-1\n    description: The Firehose multi-region endpoint\n  - url: http://firehose.{region}.amazonaws.com.cn\n    variables:\n      region:\n        description: The AWS region\n        enum:\n          - cn-north-1\n          - cn-northwest-1\n        default: cn-north-1\n    description: The Firehose endpoint for China (Beijing) and China (Ningxia)\n  - url: https://firehose.{region}.amazonaws.com.cn\n    variables:\n      region:\n        description: The AWS region\n        enum:\n          - cn-north-1\n          - cn-northwest-1\n        default: cn-north-1\n    description: The Firehose endpoint for China (Beijing) and China (Ningxia)\ncomponents:\n  parameters:\n    X-Amz-Content-Sha256:\n      name: X-Amz-Content-Sha256\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-Date:\n      name: X-Amz-Date\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-Algorithm:\n      name: X-Amz-Algorithm\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-Credential:\n      name: X-Amz-Credential\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-Security-Token:\n      name: X-Amz-Security-Token\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-Signature:\n      name: X-Amz-Signature\n      in: header\n      required: false\n      schema:\n        type: string\n    X-Amz-SignedHeaders:\n      name: X-Amz-SignedHeaders\n      in: header\n      required: false\n      schema:\n        type: string\n  securitySchemes:\n    hmac:\n      type: apiKey\n      name: Authorization\n      in: header\n      description: Amazon Signature authorization v4\n      x-amazon-apigateway-authtype: awsSigv4\n  schemas:\n    CreateDeliveryStreamOutput:\n      type: object\n      properties:\n        DeliveryStreamARN:\n          $ref: \"#/components/schemas/DeliveryStreamARN\"\n    CreateDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        DeliveryStreamType:\n          $ref: \"#/components/schemas/DeliveryStreamType\"\n        KinesisStreamSourceConfiguration:\n          $ref: \"#/components/schemas/KinesisStreamSourceConfiguration\"\n        S3DestinationConfiguration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        ExtendedS3DestinationConfiguration:\n          $ref: \"#/components/schemas/ExtendedS3DestinationConfiguration\"\n        RedshiftDestinationConfiguration:\n          $ref: \"#/components/schemas/RedshiftDestinationConfiguration\"\n        ElasticsearchDestinationConfiguration:\n          $ref: \"#/components/schemas/ElasticsearchDestinationConfiguration\"\n        SplunkDestinationConfiguration:\n          $ref: \"#/components/schemas/SplunkDestinationConfiguration\"\n        Tags:\n          $ref: \"#/components/schemas/TagDeliveryStreamInputTagList\"\n    InvalidArgumentException: {}\n    LimitExceededException: {}\n    ResourceInUseException: {}\n    DeleteDeliveryStreamOutput:\n      type: object\n      properties: {}\n    DeleteDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n    ResourceNotFoundException: {}\n    DescribeDeliveryStreamOutput:\n      type: object\n      required:\n        - DeliveryStreamDescription\n      properties:\n        DeliveryStreamDescription:\n          $ref: \"#/components/schemas/DeliveryStreamDescription\"\n    DescribeDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        Limit:\n          $ref: \"#/components/schemas/DescribeDeliveryStreamInputLimit\"\n        ExclusiveStartDestinationId:\n          $ref: \"#/components/schemas/DestinationId\"\n    ListDeliveryStreamsOutput:\n      type: object\n      required:\n        - DeliveryStreamNames\n        - HasMoreDeliveryStreams\n      properties:\n        DeliveryStreamNames:\n          $ref: \"#/components/schemas/DeliveryStreamNameList\"\n        HasMoreDeliveryStreams:\n          $ref: \"#/components/schemas/BooleanObject\"\n    ListDeliveryStreamsInput:\n      type: object\n      properties:\n        Limit:\n          $ref: \"#/components/schemas/ListDeliveryStreamsInputLimit\"\n        DeliveryStreamType:\n          $ref: \"#/components/schemas/DeliveryStreamType\"\n        ExclusiveStartDeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n    ListTagsForDeliveryStreamOutput:\n      type: object\n      required:\n        - Tags\n        - HasMoreTags\n      properties:\n        Tags:\n          $ref: \"#/components/schemas/ListTagsForDeliveryStreamOutputTagList\"\n        HasMoreTags:\n          $ref: \"#/components/schemas/BooleanObject\"\n    ListTagsForDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        ExclusiveStartTagKey:\n          $ref: \"#/components/schemas/TagKey\"\n        Limit:\n          $ref: \"#/components/schemas/ListTagsForDeliveryStreamInputLimit\"\n    PutRecordOutput:\n      type: object\n      required:\n        - RecordId\n      properties:\n        RecordId:\n          $ref: \"#/components/schemas/PutResponseRecordId\"\n        Encrypted:\n          $ref: \"#/components/schemas/BooleanObject\"\n    PutRecordInput:\n      type: object\n      required:\n        - DeliveryStreamName\n        - Record\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        Record:\n          $ref: \"#/components/schemas/Record\"\n    ServiceUnavailableException: {}\n    PutRecordBatchOutput:\n      type: object\n      required:\n        - FailedPutCount\n        - RequestResponses\n      properties:\n        FailedPutCount:\n          $ref: \"#/components/schemas/NonNegativeIntegerObject\"\n        Encrypted:\n          $ref: \"#/components/schemas/BooleanObject\"\n        RequestResponses:\n          $ref: \"#/components/schemas/PutRecordBatchResponseEntryList\"\n    PutRecordBatchInput:\n      type: object\n      required:\n        - DeliveryStreamName\n        - Records\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        Records:\n          $ref: \"#/components/schemas/PutRecordBatchRequestEntryList\"\n    StartDeliveryStreamEncryptionOutput:\n      type: object\n      properties: {}\n    StartDeliveryStreamEncryptionInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n    StopDeliveryStreamEncryptionOutput:\n      type: object\n      properties: {}\n    StopDeliveryStreamEncryptionInput:\n      type: object\n      required:\n        - DeliveryStreamName\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n    TagDeliveryStreamOutput:\n      type: object\n      properties: {}\n    TagDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n        - Tags\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        Tags:\n          $ref: \"#/components/schemas/TagDeliveryStreamInputTagList\"\n    UntagDeliveryStreamOutput:\n      type: object\n      properties: {}\n    UntagDeliveryStreamInput:\n      type: object\n      required:\n        - DeliveryStreamName\n        - TagKeys\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        TagKeys:\n          $ref: \"#/components/schemas/TagKeyList\"\n    UpdateDestinationOutput:\n      type: object\n      properties: {}\n    UpdateDestinationInput:\n      type: object\n      required:\n        - DeliveryStreamName\n        - CurrentDeliveryStreamVersionId\n        - DestinationId\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        CurrentDeliveryStreamVersionId:\n          $ref: \"#/components/schemas/DeliveryStreamVersionId\"\n        DestinationId:\n          $ref: \"#/components/schemas/DestinationId\"\n        S3DestinationUpdate:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        ExtendedS3DestinationUpdate:\n          $ref: \"#/components/schemas/ExtendedS3DestinationUpdate\"\n        RedshiftDestinationUpdate:\n          $ref: \"#/components/schemas/RedshiftDestinationUpdate\"\n        ElasticsearchDestinationUpdate:\n          $ref: \"#/components/schemas/ElasticsearchDestinationUpdate\"\n        SplunkDestinationUpdate:\n          $ref: \"#/components/schemas/SplunkDestinationUpdate\"\n    ConcurrentModificationException: {}\n    AWSKMSKeyARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 512\n    BlockSizeBytes:\n      type: integer\n      minimum: 67108864\n    BooleanObject:\n      type: boolean\n    BucketARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 2048\n    SizeInMBs:\n      type: integer\n      minimum: 1\n      maximum: 128\n    IntervalInSeconds:\n      type: integer\n      minimum: 60\n      maximum: 900\n    BufferingHints:\n      type: object\n      properties:\n        SizeInMBs:\n          $ref: \"#/components/schemas/SizeInMBs\"\n        IntervalInSeconds:\n          $ref: \"#/components/schemas/IntervalInSeconds\"\n      description: Describes hints for the buffering to perform before delivering data to\n        the destination. These options are treated as hints, and therefore\n        Kinesis Data Firehose might choose to use different values when it is\n        optimal.\n    LogGroupName:\n      type: string\n    LogStreamName:\n      type: string\n    CloudWatchLoggingOptions:\n      type: object\n      properties:\n        Enabled:\n          $ref: \"#/components/schemas/BooleanObject\"\n        LogGroupName:\n          $ref: \"#/components/schemas/LogGroupName\"\n        LogStreamName:\n          $ref: \"#/components/schemas/LogStreamName\"\n      description: Describes the Amazon CloudWatch logging options for your delivery stream.\n    ClusterJDBCURL:\n      type: string\n      pattern: jdbc:(redshift|postgresql)://((?!-)[A-Za-z0-9-]{1,63}(?\u003c!-)\\.)+redshift\\.amazonaws\\.com:\\d{1,5}/[a-zA-Z0-9_$]+\n      minLength: 1\n    NonEmptyString:\n      type: string\n      pattern: ^(?!\\s*$).+\n    ColumnToJsonKeyMappings:\n      type: object\n      additionalProperties:\n        $ref: \"#/components/schemas/NonEmptyString\"\n    CompressionFormat:\n      type: string\n      enum:\n        - UNCOMPRESSED\n        - GZIP\n        - ZIP\n        - Snappy\n    DataTableName:\n      type: string\n      minLength: 1\n    DataTableColumns:\n      type: string\n    CopyOptions:\n      type: string\n    CopyCommand:\n      type: object\n      required:\n        - DataTableName\n      properties:\n        DataTableName:\n          $ref: \"#/components/schemas/DataTableName\"\n        DataTableColumns:\n          $ref: \"#/components/schemas/DataTableColumns\"\n        CopyOptions:\n          $ref: \"#/components/schemas/CopyOptions\"\n      description: Describes a \u003ccode\u003eCOPY\u003c/code\u003e command for Amazon Redshift.\n    DeliveryStreamName:\n      type: string\n      pattern: \"[a-zA-Z0-9_.-]+\"\n      minLength: 1\n      maxLength: 64\n    DeliveryStreamType:\n      type: string\n      enum:\n        - DirectPut\n        - KinesisStreamAsSource\n    KinesisStreamSourceConfiguration:\n      type: object\n      required:\n        - KinesisStreamARN\n        - RoleARN\n      properties:\n        KinesisStreamARN:\n          $ref: \"#/components/schemas/KinesisStreamARN\"\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n      description: The stream and role Amazon Resource Names (ARNs) for a Kinesis data\n        stream used as the source for a delivery stream.\n    S3DestinationConfiguration:\n      type: object\n      required:\n        - RoleARN\n        - BucketARN\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes the configuration of a destination in Amazon S3.\n    ExtendedS3DestinationConfiguration:\n      type: object\n      required:\n        - RoleARN\n        - BucketARN\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/S3BackupMode\"\n        S3BackupConfiguration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        DataFormatConversionConfiguration:\n          $ref: \"#/components/schemas/DataFormatConversionConfiguration\"\n      description: Describes the configuration of a destination in Amazon S3.\n    RedshiftDestinationConfiguration:\n      type: object\n      required:\n        - RoleARN\n        - ClusterJDBCURL\n        - CopyCommand\n        - Username\n        - Password\n        - S3Configuration\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        ClusterJDBCURL:\n          $ref: \"#/components/schemas/ClusterJDBCURL\"\n        CopyCommand:\n          $ref: \"#/components/schemas/CopyCommand\"\n        Username:\n          $ref: \"#/components/schemas/Username\"\n        Password:\n          $ref: \"#/components/schemas/Password\"\n        RetryOptions:\n          $ref: \"#/components/schemas/RedshiftRetryOptions\"\n        S3Configuration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/RedshiftS3BackupMode\"\n        S3BackupConfiguration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes the configuration of a destination in Amazon Redshift.\n    ElasticsearchDestinationConfiguration:\n      type: object\n      required:\n        - RoleARN\n        - DomainARN\n        - IndexName\n        - TypeName\n        - S3Configuration\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        DomainARN:\n          $ref: \"#/components/schemas/ElasticsearchDomainARN\"\n        IndexName:\n          $ref: \"#/components/schemas/ElasticsearchIndexName\"\n        TypeName:\n          $ref: \"#/components/schemas/ElasticsearchTypeName\"\n        IndexRotationPeriod:\n          $ref: \"#/components/schemas/ElasticsearchIndexRotationPeriod\"\n        BufferingHints:\n          $ref: \"#/components/schemas/ElasticsearchBufferingHints\"\n        RetryOptions:\n          $ref: \"#/components/schemas/ElasticsearchRetryOptions\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/ElasticsearchS3BackupMode\"\n        S3Configuration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes the configuration of a destination in Amazon ES.\n    SplunkDestinationConfiguration:\n      type: object\n      required:\n        - HECEndpoint\n        - HECEndpointType\n        - HECToken\n        - S3Configuration\n      properties:\n        HECEndpoint:\n          $ref: \"#/components/schemas/HECEndpoint\"\n        HECEndpointType:\n          $ref: \"#/components/schemas/HECEndpointType\"\n        HECToken:\n          $ref: \"#/components/schemas/HECToken\"\n        HECAcknowledgmentTimeoutInSeconds:\n          $ref: \"#/components/schemas/HECAcknowledgmentTimeoutInSeconds\"\n        RetryOptions:\n          $ref: \"#/components/schemas/SplunkRetryOptions\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/SplunkS3BackupMode\"\n        S3Configuration:\n          $ref: \"#/components/schemas/S3DestinationConfiguration\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes the configuration of a destination in Splunk.\n    TagDeliveryStreamInputTagList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/Tag\"\n      minItems: 1\n      maxItems: 50\n    DeliveryStreamARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 512\n    Data:\n      type: string\n      minLength: 0\n      maxLength: 1024000\n    SchemaConfiguration:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n        CatalogId:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n        DatabaseName:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n        TableName:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n        Region:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n        VersionId:\n          $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n      description: Specifies the schema to which you want Kinesis Data Firehose to\n        configure your data before it writes it to Amazon S3.\n    InputFormatConfiguration:\n      type: object\n      properties:\n        Deserializer:\n          $ref: \"#/components/schemas/Deserializer\"\n      description: Specifies the deserializer you want to use to convert the format of the\n        input data.\n    OutputFormatConfiguration:\n      type: object\n      properties:\n        Serializer:\n          $ref: \"#/components/schemas/Serializer\"\n      description: Specifies the serializer that you want Kinesis Data Firehose to use to\n        convert the format of your data before it writes it to Amazon S3.\n    DataFormatConversionConfiguration:\n      type: object\n      properties:\n        SchemaConfiguration:\n          $ref: \"#/components/schemas/SchemaConfiguration\"\n        InputFormatConfiguration:\n          $ref: \"#/components/schemas/InputFormatConfiguration\"\n        OutputFormatConfiguration:\n          $ref: \"#/components/schemas/OutputFormatConfiguration\"\n        Enabled:\n          $ref: \"#/components/schemas/BooleanObject\"\n      description: Specifies that you want Kinesis Data Firehose to convert data from the\n        JSON format to the Parquet or ORC format before writing it to Amazon S3.\n        Kinesis Data Firehose uses the serializer and deserializer that you\n        specify, in addition to the column information from the AWS Glue table,\n        to deserialize your input data from JSON and then serialize it to the\n        Parquet or ORC format. For more information, see \u003ca\n        href=\"https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html\"\u003eKinesis\n        Data Firehose Record Format Conversion\u003c/a\u003e.\n    DeliveryStartTimestamp:\n      type: string\n      format: date-time\n    DeliveryStreamStatus:\n      type: string\n      enum:\n        - CREATING\n        - DELETING\n        - ACTIVE\n    DeliveryStreamEncryptionConfiguration:\n      type: object\n      properties:\n        Status:\n          $ref: \"#/components/schemas/DeliveryStreamEncryptionStatus\"\n      description: Indicates the server-side encryption (SSE) status for the delivery\n        stream.\n    DeliveryStreamVersionId:\n      type: string\n      pattern: \"[0-9]+\"\n      minLength: 1\n      maxLength: 50\n    Timestamp:\n      type: string\n      format: date-time\n    SourceDescription:\n      type: object\n      properties:\n        KinesisStreamSourceDescription:\n          $ref: \"#/components/schemas/KinesisStreamSourceDescription\"\n      description: Details about a Kinesis data stream used as the source for a Kinesis\n        Data Firehose delivery stream.\n    DestinationDescriptionList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/DestinationDescription\"\n    DeliveryStreamDescription:\n      type: object\n      required:\n        - DeliveryStreamName\n        - DeliveryStreamARN\n        - DeliveryStreamStatus\n        - DeliveryStreamType\n        - VersionId\n        - Destinations\n        - HasMoreDestinations\n      properties:\n        DeliveryStreamName:\n          $ref: \"#/components/schemas/DeliveryStreamName\"\n        DeliveryStreamARN:\n          $ref: \"#/components/schemas/DeliveryStreamARN\"\n        DeliveryStreamStatus:\n          $ref: \"#/components/schemas/DeliveryStreamStatus\"\n        DeliveryStreamEncryptionConfiguration:\n          $ref: \"#/components/schemas/DeliveryStreamEncryptionConfiguration\"\n        DeliveryStreamType:\n          $ref: \"#/components/schemas/DeliveryStreamType\"\n        VersionId:\n          $ref: \"#/components/schemas/DeliveryStreamVersionId\"\n        CreateTimestamp:\n          $ref: \"#/components/schemas/Timestamp\"\n        LastUpdateTimestamp:\n          $ref: \"#/components/schemas/Timestamp\"\n        Source:\n          $ref: \"#/components/schemas/SourceDescription\"\n        Destinations:\n          $ref: \"#/components/schemas/DestinationDescriptionList\"\n        HasMoreDestinations:\n          $ref: \"#/components/schemas/BooleanObject\"\n      description: Contains information about a delivery stream.\n    DeliveryStreamEncryptionStatus:\n      type: string\n      enum:\n        - ENABLED\n        - ENABLING\n        - DISABLED\n        - DISABLING\n    DeliveryStreamNameList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/DeliveryStreamName\"\n    DescribeDeliveryStreamInputLimit:\n      type: integer\n      minimum: 1\n      maximum: 10000\n    DestinationId:\n      type: string\n      minLength: 1\n      maxLength: 100\n    OpenXJsonSerDe:\n      type: object\n      properties:\n        ConvertDotsInJsonKeysToUnderscores:\n          $ref: \"#/components/schemas/BooleanObject\"\n        CaseInsensitive:\n          $ref: \"#/components/schemas/BooleanObject\"\n        ColumnToJsonKeyMappings:\n          $ref: \"#/components/schemas/ColumnToJsonKeyMappings\"\n      description: The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data,\n        which means converting it from the JSON format in preparation for\n        serializing it to the Parquet or ORC format. This is one of two\n        deserializers you can choose, depending on which one offers the\n        functionality you need. The other option is the native Hive / HCatalog\n        JsonSerDe.\n    HiveJsonSerDe:\n      type: object\n      properties:\n        TimestampFormats:\n          $ref: \"#/components/schemas/ListOfNonEmptyStrings\"\n      description: The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for\n        deserializing data, which means converting it from the JSON format in\n        preparation for serializing it to the Parquet or ORC format. This is one\n        of two deserializers you can choose, depending on which one offers the\n        functionality you need. The other option is the OpenX SerDe.\n    Deserializer:\n      type: object\n      properties:\n        OpenXJsonSerDe:\n          $ref: \"#/components/schemas/OpenXJsonSerDe\"\n        HiveJsonSerDe:\n          $ref: \"#/components/schemas/HiveJsonSerDe\"\n      description: 'The deserializer you want Kinesis Data Firehose to use for converting\n        the input data from JSON. Kinesis Data Firehose then serializes the data\n        to its final format using the \u003ca\u003eSerializer\u003c/a\u003e. Kinesis Data Firehose\n        supports two types of deserializers: the \u003ca\n        href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON\"\u003eApache\n        Hive JSON SerDe\u003c/a\u003e and the \u003ca\n        href=\"https://github.com/rcongiu/Hive-JSON-Serde\"\u003eOpenX JSON SerDe\u003c/a\u003e.'\n    S3DestinationDescription:\n      type: object\n      required:\n        - RoleARN\n        - BucketARN\n        - BufferingHints\n        - CompressionFormat\n        - EncryptionConfiguration\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes a destination in Amazon S3.\n    ExtendedS3DestinationDescription:\n      type: object\n      required:\n        - RoleARN\n        - BucketARN\n        - BufferingHints\n        - CompressionFormat\n        - EncryptionConfiguration\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/S3BackupMode\"\n        S3BackupDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        DataFormatConversionConfiguration:\n          $ref: \"#/components/schemas/DataFormatConversionConfiguration\"\n      description: Describes a destination in Amazon S3.\n    RedshiftDestinationDescription:\n      type: object\n      required:\n        - RoleARN\n        - ClusterJDBCURL\n        - CopyCommand\n        - Username\n        - S3DestinationDescription\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        ClusterJDBCURL:\n          $ref: \"#/components/schemas/ClusterJDBCURL\"\n        CopyCommand:\n          $ref: \"#/components/schemas/CopyCommand\"\n        Username:\n          $ref: \"#/components/schemas/Username\"\n        RetryOptions:\n          $ref: \"#/components/schemas/RedshiftRetryOptions\"\n        S3DestinationDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/RedshiftS3BackupMode\"\n        S3BackupDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes a destination in Amazon Redshift.\n    ElasticsearchDestinationDescription:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        DomainARN:\n          $ref: \"#/components/schemas/ElasticsearchDomainARN\"\n        IndexName:\n          $ref: \"#/components/schemas/ElasticsearchIndexName\"\n        TypeName:\n          $ref: \"#/components/schemas/ElasticsearchTypeName\"\n        IndexRotationPeriod:\n          $ref: \"#/components/schemas/ElasticsearchIndexRotationPeriod\"\n        BufferingHints:\n          $ref: \"#/components/schemas/ElasticsearchBufferingHints\"\n        RetryOptions:\n          $ref: \"#/components/schemas/ElasticsearchRetryOptions\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/ElasticsearchS3BackupMode\"\n        S3DestinationDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: The destination description in Amazon ES.\n    SplunkDestinationDescription:\n      type: object\n      properties:\n        HECEndpoint:\n          $ref: \"#/components/schemas/HECEndpoint\"\n        HECEndpointType:\n          $ref: \"#/components/schemas/HECEndpointType\"\n        HECToken:\n          $ref: \"#/components/schemas/HECToken\"\n        HECAcknowledgmentTimeoutInSeconds:\n          $ref: \"#/components/schemas/HECAcknowledgmentTimeoutInSeconds\"\n        RetryOptions:\n          $ref: \"#/components/schemas/SplunkRetryOptions\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/SplunkS3BackupMode\"\n        S3DestinationDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes a destination in Splunk.\n    DestinationDescription:\n      type: object\n      required:\n        - DestinationId\n      properties:\n        DestinationId:\n          $ref: \"#/components/schemas/DestinationId\"\n        S3DestinationDescription:\n          $ref: \"#/components/schemas/S3DestinationDescription\"\n        ExtendedS3DestinationDescription:\n          $ref: \"#/components/schemas/ExtendedS3DestinationDescription\"\n        RedshiftDestinationDescription:\n          $ref: \"#/components/schemas/RedshiftDestinationDescription\"\n        ElasticsearchDestinationDescription:\n          $ref: \"#/components/schemas/ElasticsearchDestinationDescription\"\n        SplunkDestinationDescription:\n          $ref: \"#/components/schemas/SplunkDestinationDescription\"\n      description: Describes the destination for a delivery stream.\n    ElasticsearchBufferingIntervalInSeconds:\n      type: integer\n      minimum: 60\n      maximum: 900\n    ElasticsearchBufferingSizeInMBs:\n      type: integer\n      minimum: 1\n      maximum: 100\n    ElasticsearchBufferingHints:\n      type: object\n      properties:\n        IntervalInSeconds:\n          $ref: \"#/components/schemas/ElasticsearchBufferingIntervalInSeconds\"\n        SizeInMBs:\n          $ref: \"#/components/schemas/ElasticsearchBufferingSizeInMBs\"\n      description: Describes the buffering to perform before delivering data to the Amazon\n        ES destination.\n    RoleARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 512\n    ElasticsearchDomainARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 512\n    ElasticsearchIndexName:\n      type: string\n      minLength: 1\n      maxLength: 80\n    ElasticsearchTypeName:\n      type: string\n      minLength: 1\n      maxLength: 100\n    ElasticsearchIndexRotationPeriod:\n      type: string\n      enum:\n        - NoRotation\n        - OneHour\n        - OneDay\n        - OneWeek\n        - OneMonth\n    ElasticsearchRetryOptions:\n      type: object\n      properties:\n        DurationInSeconds:\n          $ref: \"#/components/schemas/ElasticsearchRetryDurationInSeconds\"\n      description: Configures retry behavior in case Kinesis Data Firehose is unable to\n        deliver documents to Amazon ES.\n    ElasticsearchS3BackupMode:\n      type: string\n      enum:\n        - FailedDocumentsOnly\n        - AllDocuments\n    ProcessingConfiguration:\n      type: object\n      properties:\n        Enabled:\n          $ref: \"#/components/schemas/BooleanObject\"\n        Processors:\n          $ref: \"#/components/schemas/ProcessorList\"\n      description: Describes a data processing configuration.\n    S3DestinationUpdate:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes an update for a destination in Amazon S3.\n    ElasticsearchDestinationUpdate:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        DomainARN:\n          $ref: \"#/components/schemas/ElasticsearchDomainARN\"\n        IndexName:\n          $ref: \"#/components/schemas/ElasticsearchIndexName\"\n        TypeName:\n          $ref: \"#/components/schemas/ElasticsearchTypeName\"\n        IndexRotationPeriod:\n          $ref: \"#/components/schemas/ElasticsearchIndexRotationPeriod\"\n        BufferingHints:\n          $ref: \"#/components/schemas/ElasticsearchBufferingHints\"\n        RetryOptions:\n          $ref: \"#/components/schemas/ElasticsearchRetryOptions\"\n        S3Update:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes an update for a destination in Amazon ES.\n    ElasticsearchRetryDurationInSeconds:\n      type: integer\n      minimum: 0\n      maximum: 7200\n    NoEncryptionConfig:\n      type: string\n      enum:\n        - NoEncryption\n    KMSEncryptionConfig:\n      type: object\n      required:\n        - AWSKMSKeyARN\n      properties:\n        AWSKMSKeyARN:\n          $ref: \"#/components/schemas/AWSKMSKeyARN\"\n      description: Describes an encryption key for a destination in Amazon S3.\n    EncryptionConfiguration:\n      type: object\n      properties:\n        NoEncryptionConfig:\n          $ref: \"#/components/schemas/NoEncryptionConfig\"\n        KMSEncryptionConfig:\n          $ref: \"#/components/schemas/KMSEncryptionConfig\"\n      description: Describes the encryption for a destination in Amazon S3.\n    ErrorCode:\n      type: string\n    ErrorMessage:\n      type: string\n    ErrorOutputPrefix:\n      type: string\n    Prefix:\n      type: string\n    S3BackupMode:\n      type: string\n      enum:\n        - Disabled\n        - Enabled\n    ExtendedS3DestinationUpdate:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        BucketARN:\n          $ref: \"#/components/schemas/BucketARN\"\n        Prefix:\n          $ref: \"#/components/schemas/Prefix\"\n        ErrorOutputPrefix:\n          $ref: \"#/components/schemas/ErrorOutputPrefix\"\n        BufferingHints:\n          $ref: \"#/components/schemas/BufferingHints\"\n        CompressionFormat:\n          $ref: \"#/components/schemas/CompressionFormat\"\n        EncryptionConfiguration:\n          $ref: \"#/components/schemas/EncryptionConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/S3BackupMode\"\n        S3BackupUpdate:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        DataFormatConversionConfiguration:\n          $ref: \"#/components/schemas/DataFormatConversionConfiguration\"\n      description: Describes an update for a destination in Amazon S3.\n    HECAcknowledgmentTimeoutInSeconds:\n      type: integer\n      minimum: 180\n      maximum: 600\n    HECEndpoint:\n      type: string\n    HECEndpointType:\n      type: string\n      enum:\n        - Raw\n        - Event\n    HECToken:\n      type: string\n    ListOfNonEmptyStrings:\n      type: array\n      items:\n        $ref: \"#/components/schemas/NonEmptyString\"\n    KinesisStreamARN:\n      type: string\n      pattern: arn:.*\n      minLength: 1\n      maxLength: 512\n    KinesisStreamSourceDescription:\n      type: object\n      properties:\n        KinesisStreamARN:\n          $ref: \"#/components/schemas/KinesisStreamARN\"\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        DeliveryStartTimestamp:\n          $ref: \"#/components/schemas/DeliveryStartTimestamp\"\n      description: Details about a Kinesis data stream used as the source for a Kinesis\n        Data Firehose delivery stream.\n    ListDeliveryStreamsInputLimit:\n      type: integer\n      minimum: 1\n      maximum: 10000\n    NonEmptyStringWithoutWhitespace:\n      type: string\n      pattern: ^\\S+$\n    ListOfNonEmptyStringsWithoutWhitespace:\n      type: array\n      items:\n        $ref: \"#/components/schemas/NonEmptyStringWithoutWhitespace\"\n    TagKey:\n      type: string\n      minLength: 1\n      maxLength: 128\n    ListTagsForDeliveryStreamInputLimit:\n      type: integer\n      minimum: 1\n      maximum: 50\n    ListTagsForDeliveryStreamOutputTagList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/Tag\"\n      minItems: 0\n      maxItems: 50\n    Tag:\n      type: object\n      required:\n        - Key\n      properties:\n        Key:\n          $ref: \"#/components/schemas/TagKey\"\n        Value:\n          $ref: \"#/components/schemas/TagValue\"\n      description: Metadata that you can assign to a delivery stream, consisting of a\n        key-value pair.\n    NonNegativeIntegerObject:\n      type: integer\n      minimum: 0\n    OrcCompression:\n      type: string\n      enum:\n        - NONE\n        - ZLIB\n        - SNAPPY\n    OrcFormatVersion:\n      type: string\n      enum:\n        - V0_11\n        - V0_12\n    OrcRowIndexStride:\n      type: integer\n      minimum: 1000\n    OrcStripeSizeBytes:\n      type: integer\n      minimum: 8388608\n    Proportion:\n      type: number\n      format: double\n      minimum: 0\n      maximum: 1\n    OrcSerDe:\n      type: object\n      properties:\n        StripeSizeBytes:\n          $ref: \"#/components/schemas/OrcStripeSizeBytes\"\n        BlockSizeBytes:\n          $ref: \"#/components/schemas/BlockSizeBytes\"\n        RowIndexStride:\n          $ref: \"#/components/schemas/OrcRowIndexStride\"\n        EnablePadding:\n          $ref: \"#/components/schemas/BooleanObject\"\n        PaddingTolerance:\n          $ref: \"#/components/schemas/Proportion\"\n        Compression:\n          $ref: \"#/components/schemas/OrcCompression\"\n        BloomFilterColumns:\n          $ref: \"#/components/schemas/ListOfNonEmptyStringsWithoutWhitespace\"\n        BloomFilterFalsePositiveProbability:\n          $ref: \"#/components/schemas/Proportion\"\n        DictionaryKeyThreshold:\n          $ref: \"#/components/schemas/Proportion\"\n        FormatVersion:\n          $ref: \"#/components/schemas/OrcFormatVersion\"\n      description: A serializer to use for converting data to the ORC format before storing\n        it in Amazon S3. For more information, see \u003ca\n        href=\"https://orc.apache.org/docs/\"\u003eApache ORC\u003c/a\u003e.\n    Serializer:\n      type: object\n      properties:\n        ParquetSerDe:\n          $ref: \"#/components/schemas/ParquetSerDe\"\n        OrcSerDe:\n          $ref: \"#/components/schemas/OrcSerDe\"\n      description: 'The serializer that you want Kinesis Data Firehose to use to convert\n        data to the target format before writing it to Amazon S3. Kinesis Data\n        Firehose supports two types of serializers: the \u003ca\n        href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html\"\u003eORC\n        SerDe\u003c/a\u003e and the \u003ca\n        href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html\"\u003eParquet\n        SerDe\u003c/a\u003e.'\n    ParquetCompression:\n      type: string\n      enum:\n        - UNCOMPRESSED\n        - GZIP\n        - SNAPPY\n    ParquetPageSizeBytes:\n      type: integer\n      minimum: 65536\n    ParquetWriterVersion:\n      type: string\n      enum:\n        - V1\n        - V2\n    ParquetSerDe:\n      type: object\n      properties:\n        BlockSizeBytes:\n          $ref: \"#/components/schemas/BlockSizeBytes\"\n        PageSizeBytes:\n          $ref: \"#/components/schemas/ParquetPageSizeBytes\"\n        Compression:\n          $ref: \"#/components/schemas/ParquetCompression\"\n        EnableDictionaryCompression:\n          $ref: \"#/components/schemas/BooleanObject\"\n        MaxPaddingBytes:\n          $ref: \"#/components/schemas/NonNegativeIntegerObject\"\n        WriterVersion:\n          $ref: \"#/components/schemas/ParquetWriterVersion\"\n      description: A serializer to use for converting data to the Parquet format before\n        storing it in Amazon S3. For more information, see \u003ca\n        href=\"https://parquet.apache.org/documentation/latest/\"\u003eApache\n        Parquet\u003c/a\u003e.\n    Password:\n      type: string\n      minLength: 6\n      format: password\n    ProcessorList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/Processor\"\n    ProcessorType:\n      type: string\n      enum:\n        - Lambda\n    ProcessorParameterList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/ProcessorParameter\"\n    Processor:\n      type: object\n      required:\n        - Type\n      properties:\n        Type:\n          $ref: \"#/components/schemas/ProcessorType\"\n        Parameters:\n          $ref: \"#/components/schemas/ProcessorParameterList\"\n      description: Describes a data processor.\n    ProcessorParameterName:\n      type: string\n      enum:\n        - LambdaArn\n        - NumberOfRetries\n        - RoleArn\n        - BufferSizeInMBs\n        - BufferIntervalInSeconds\n    ProcessorParameterValue:\n      type: string\n      minLength: 1\n      maxLength: 512\n    ProcessorParameter:\n      type: object\n      required:\n        - ParameterName\n        - ParameterValue\n      properties:\n        ParameterName:\n          $ref: \"#/components/schemas/ProcessorParameterName\"\n        ParameterValue:\n          $ref: \"#/components/schemas/ProcessorParameterValue\"\n      description: Describes the processor parameter.\n    PutRecordBatchRequestEntryList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/Record\"\n      minItems: 1\n      maxItems: 500\n    PutRecordBatchResponseEntryList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/PutRecordBatchResponseEntry\"\n      minItems: 1\n      maxItems: 500\n    Record:\n      type: object\n      required:\n        - Data\n      properties:\n        Data:\n          $ref: \"#/components/schemas/Data\"\n      description: The unit of data in a delivery stream.\n    PutResponseRecordId:\n      type: string\n      minLength: 1\n    PutRecordBatchResponseEntry:\n      type: object\n      properties:\n        RecordId:\n          $ref: \"#/components/schemas/PutResponseRecordId\"\n        ErrorCode:\n          $ref: \"#/components/schemas/ErrorCode\"\n        ErrorMessage:\n          $ref: \"#/components/schemas/ErrorMessage\"\n      description: Contains the result for an individual record from a\n        \u003ca\u003ePutRecordBatch\u003c/a\u003e request. If the record is successfully added to\n        your delivery stream, it receives a record ID. If the record fails to be\n        added to your delivery stream, the result includes an error code and an\n        error message.\n    Username:\n      type: string\n      minLength: 1\n      format: password\n    RedshiftRetryOptions:\n      type: object\n      properties:\n        DurationInSeconds:\n          $ref: \"#/components/schemas/RedshiftRetryDurationInSeconds\"\n      description: Configures retry behavior in case Kinesis Data Firehose is unable to\n        deliver documents to Amazon Redshift.\n    RedshiftS3BackupMode:\n      type: string\n      enum:\n        - Disabled\n        - Enabled\n    RedshiftDestinationUpdate:\n      type: object\n      properties:\n        RoleARN:\n          $ref: \"#/components/schemas/RoleARN\"\n        ClusterJDBCURL:\n          $ref: \"#/components/schemas/ClusterJDBCURL\"\n        CopyCommand:\n          $ref: \"#/components/schemas/CopyCommand\"\n        Username:\n          $ref: \"#/components/schemas/Username\"\n        Password:\n          $ref: \"#/components/schemas/Password\"\n        RetryOptions:\n          $ref: \"#/components/schemas/RedshiftRetryOptions\"\n        S3Update:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/RedshiftS3BackupMode\"\n        S3BackupUpdate:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes an update for a destination in Amazon Redshift.\n    RedshiftRetryDurationInSeconds:\n      type: integer\n      minimum: 0\n      maximum: 7200\n    SplunkRetryOptions:\n      type: object\n      properties:\n        DurationInSeconds:\n          $ref: \"#/components/schemas/SplunkRetryDurationInSeconds\"\n      description: Configures retry behavior in case Kinesis Data Firehose is unable to\n        deliver documents to Splunk, or if it doesn't receive an acknowledgment\n        from Splunk.\n    SplunkS3BackupMode:\n      type: string\n      enum:\n        - FailedEventsOnly\n        - AllEvents\n    SplunkDestinationUpdate:\n      type: object\n      properties:\n        HECEndpoint:\n          $ref: \"#/components/schemas/HECEndpoint\"\n        HECEndpointType:\n          $ref: \"#/components/schemas/HECEndpointType\"\n        HECToken:\n          $ref: \"#/components/schemas/HECToken\"\n        HECAcknowledgmentTimeoutInSeconds:\n          $ref: \"#/components/schemas/HECAcknowledgmentTimeoutInSeconds\"\n        RetryOptions:\n          $ref: \"#/components/schemas/SplunkRetryOptions\"\n        S3BackupMode:\n          $ref: \"#/components/schemas/SplunkS3BackupMode\"\n        S3Update:\n          $ref: \"#/components/schemas/S3DestinationUpdate\"\n        ProcessingConfiguration:\n          $ref: \"#/components/schemas/ProcessingConfiguration\"\n        CloudWatchLoggingOptions:\n          $ref: \"#/components/schemas/CloudWatchLoggingOptions\"\n      description: Describes an update for a destination in Splunk.\n    SplunkRetryDurationInSeconds:\n      type: integer\n      minimum: 0\n      maximum: 7200\n    TagValue:\n      type: string\n      minLength: 0\n      maxLength: 256\n    TagKeyList:\n      type: array\n      items:\n        $ref: \"#/components/schemas/TagKey\"\n      minItems: 1\n      maxItems: 50\n"
		}
	},
	"Error": "buildIR: make ir: path \"/#X-Amz-Target=Firehose_20150804.UpdateDestination\": post: requestBody: contents: application/json: generate schema: field ExtendedS3DestinationUpdate: field DataFormatConversionConfiguration: field InputFormatConfiguration: field Deserializer: field HiveJsonSerDe: field TimestampFormats: item: string validator: pattern: error parsing regexp: invalid or unsupported Perl syntax: `(?!`"
}