{
	"File": {
		"__typename": "FileMatch",
		"repository": {
			"name": "github.com/restful-ma/thresholds"
		},
		"file": {
			"name": "azure.com-cognitiveservices-ComputerVision-1.0-swagger.yaml",
			"size": 0,
			"path": "benchmark-repository/openapi/azure.com-cognitiveservices-ComputerVision-1.0-swagger.yaml",
			"byteSize": 55615,
			"content": "openapi: 3.0.0\ninfo:\n  description: The Computer Vision API provides state-of-the-art algorithms to process\n    images and return information. For example, it can be used to determine if\n    an image contains mature content, or it can be used to find all the faces in\n    an image.  It also has other features like estimating dominant and accent\n    colors, categorizing the content of images, and describing an image with\n    complete English sentences.  Additionally, it can also intelligently\n    generate images thumbnails for displaying large images effectively.\n  title: Computer Vision\n  version: \"1.0\"\n  x-apisguru-categories:\n    - cloud\n  x-logo:\n    url: https://assets.onestore.ms/cdnfiles/onestorerolling-1606-01000/shell/v3/images/logo/microsoft.png\n  x-origin:\n    - format: swagger\n      url: https://raw.githubusercontent.com/Azure/azure-rest-api-specs/master/specification/cognitiveservices/data-plane/ComputerVision/stable/v1.0/ComputerVision.json\n      version: \"2.0\"\n  x-providerName: azure.com\n  x-serviceName: cognitiveservices-ComputerVision\n  x-tags:\n    - Azure\n    - Microsoft\nsecurity:\n  - apim_key: []\npaths:\n  /analyze:\n    post:\n      description: This operation extracts a rich set of visual features based on the image\n        content. Two input methods are supported -- (1) Uploading an image or\n        (2) specifying an image URL.  Within your request, there is an optional\n        parameter to allow you to choose which features to return.  By default,\n        image categories are returned in the response.\n      operationId: AnalyzeImage\n      parameters:\n        - $ref: \"#/components/parameters/VisualFeatures\"\n        - description: A string indicating which domain-specific details to return.\n            Multiple values should be comma-separated. Valid visual feature\n            types include:Celebrities - identifies celebrities if detected in\n            the image.\n          in: query\n          name: details\n          required: false\n          style: form\n          explode: false\n          schema:\n            type: array\n            items:\n              enum:\n                - Celebrities\n                - Landmarks\n              type: string\n              x-ms-enum:\n                modelAsString: false\n                name: Details\n              nullable: false\n          examples:\n            Successful Analyze with Url request:\n              value: Celebrities\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: The response include the extracted features in JSON format.Here is\n            the definitions for enumeration typesClipartTypeNon-clipart =\n            0,  ambiguous = 1, normal-clipart = 2, good-clipart =\n            3.LineDrawingTypeNon-LineDrawing = 0,LineDrawing = 1.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ImageAnalysis\"\n              examples:\n                Successful Analyze with Url request:\n                  $ref: \"#/components/examples/Successful_Analyze_with_Url_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /describe:\n    post:\n      description: This operation generates a description of an image in human readable\n        language with complete sentences.  The description is based on a\n        collection of content tags, which are also returned by the operation.\n        More than one description can be generated for each image.  Descriptions\n        are ordered by their confidence score. All descriptions are in English.\n        Two input methods are supported -- (1) Uploading an image or (2)\n        specifying an image URL.A successful response will be returned in\n        JSON.  If the request failed, the response will contain an error code\n        and a message to help understand what went wrong.\n      operationId: DescribeImage\n      parameters:\n        - description: Maximum number of candidate descriptions to be returned.  The\n            default is 1.\n          in: query\n          name: maxCandidates\n          required: false\n          schema:\n            type: string\n            default: \"1\"\n          examples:\n            Successful Describe request:\n              value: \"1\"\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: Image description object.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ImageDescription\"\n              examples:\n                Successful Describe request:\n                  $ref: \"#/components/examples/Successful_Describe_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /generateThumbnail:\n    post:\n      description: This operation generates a thumbnail image with the user-specified width\n        and height. By default, the service analyzes the image, identifies the\n        region of interest (ROI), and generates smart cropping coordinates based\n        on the ROI. Smart cropping helps when you specify an aspect ratio that\n        differs from that of the input image. A successful response contains the\n        thumbnail image binary. If the request failed, the response contains an\n        error code and a message to help determine what went wrong.\n      operationId: GenerateThumbnail\n      parameters:\n        - description: Width of the thumbnail. It must be between 1 and 1024. Recommended\n            minimum of 50.\n          in: query\n          name: width\n          required: true\n          schema:\n            type: integer\n            minimum: 1\n            maximum: 1023\n          examples:\n            Successful Generate Thumbnail request:\n              value: \"500\"\n        - description: Height of the thumbnail. It must be between 1 and 1024. Recommended\n            minimum of 50.\n          in: query\n          name: height\n          required: true\n          schema:\n            type: integer\n            minimum: 1\n            maximum: 1023\n          examples:\n            Successful Generate Thumbnail request:\n              value: \"500\"\n        - description: Boolean flag for enabling smart cropping.\n          in: query\n          name: smartCropping\n          required: false\n          schema:\n            type: boolean\n            default: false\n          examples:\n            Successful Generate Thumbnail request:\n              value: true\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: The generated thumbnail in binary format.\n          content:\n            application/octet-stream:\n              schema:\n                type: string\n                format: binary\n              examples:\n                Successful Generate Thumbnail request:\n                  $ref: \"#/components/examples/Successful_Generate_Thumbnail_request\"\n        default:\n          description: Error response.\n          content:\n            application/octet-stream:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /models:\n    get:\n      description: \"This operation returns the list of domain-specific models that are\n        supported by the Computer Vision API.  Currently, the API only supports\n        one domain-specific model: a celebrity recognizer. A successful response\n        will be returned in JSON.  If the request failed, the response will\n        contain an error code and a message to help understand what went wrong.\"\n      operationId: ListModels\n      responses:\n        \"200\":\n          description: List of available domain models.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ListModelsResult\"\n              examples:\n                Successful List Domains request:\n                  $ref: \"#/components/examples/Successful_List_Domains_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  \"/models/{model}/analyze\":\n    post:\n      description: \"This operation recognizes content within an image by applying a\n        domain-specific model.  The list of domain-specific models that are\n        supported by the Computer Vision API can be retrieved using the /models\n        GET request.  Currently, the API only provides a single domain-specific\n        model: celebrities. Two input methods are supported -- (1) Uploading an\n        image or (2) specifying an image URL. A successful response will be\n        returned in JSON.  If the request failed, the response will contain an\n        error code and a message to help understand what went wrong.\"\n      operationId: AnalyzeImageByDomain\n      parameters:\n        - description: The domain-specific content to recognize.\n          in: path\n          name: model\n          required: true\n          schema:\n            type: string\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: Analysis result based on the domain model\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DomainModelResults\"\n              examples:\n                Successful Domain Model analysis request:\n                  $ref: \"#/components/examples/Successful_Domain_Model_analysis_req\\\n                    uest\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /ocr:\n    post:\n      description: Optical Character Recognition (OCR) detects printed text in an image and\n        extracts the recognized characters into a machine-usable character\n        stream.   Upon success, the OCR results will be returned. Upon failure,\n        the error code together with an error message will be returned. The\n        error code can be one of InvalidImageUrl, InvalidImageFormat,\n        InvalidImageSize, NotSupportedImage,  NotSupportedLanguage, or\n        InternalServerError.\n      operationId: RecognizePrintedText\n      parameters:\n        - $ref: \"#/components/parameters/DetectOrientation\"\n        - $ref: \"#/components/parameters/OcrLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: The OCR results in the hierarchy of region/line/word. The results\n            include text, bounding box for regions, lines and words.textAngleThe\n            angle, in degrees, of the detected text with respect to the closest\n            horizontal or vertical direction. After rotating the input image\n            clockwise by this angle, the recognized text lines become horizontal\n            or vertical. In combination with the orientation property it can be\n            used to overlay recognition results correctly on the original image,\n            by rotating either the original image or recognition results by a\n            suitable angle around the center of the original image. If the angle\n            cannot be confidently detected, this property is not present. If the\n            image contains text at different angles, only part of the text will\n            be recognized correctly.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/OcrResult\"\n              examples:\n                Successful Ocr request:\n                  $ref: \"#/components/examples/Successful_Ocr_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /recognizeText:\n    post:\n      description: Recognize Text operation. When you use the Recognize Text interface, the\n        response contains a field called 'Operation-Location'. The\n        'Operation-Location' field contains the URL that you must use for your\n        Get Handwritten Text Operation Result operation.\n      operationId: RecognizeText\n      parameters:\n        - $ref: \"#/components/parameters/HandwritingBoolean\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"202\":\n          description: The service has accepted the request and will start processing\n            later. It will return Accepted immediately and include an\n            Operation-Location header. Client side should further query the\n            operation status using the URL specified in this header. The\n            operation ID will expire in 48 hours.\n          headers:\n            Operation-Location:\n              description: \"URL to query for status of the operation. The operation ID will\n                expire in 48 hours. \"\n              schema:\n                type: string\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /tag:\n    post:\n      description: This operation generates a list of words, or tags, that are relevant to\n        the content of the supplied image. The Computer Vision API can return\n        tags based on objects, living beings, scenery or actions found in\n        images. Unlike categories, tags are not organized according to a\n        hierarchical classification system, but correspond to image content.\n        Tags may contain hints to avoid ambiguity or provide context, for\n        example the tag 'cello' may be accompanied by the hint 'musical\n        instrument'. All tags are in English.\n      operationId: TagImage\n      parameters:\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageImageurl\"\n      responses:\n        \"200\":\n          description: Image tags object.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TagResult\"\n              examples:\n                Successful Tag request:\n                  $ref: \"#/components/examples/Successful_Tag_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  \"/textOperations/{operationId}\":\n    get:\n      description: This interface is used for getting text operation result. The URL to\n        this interface should be retrieved from 'Operation-Location' field\n        returned from Recognize Text interface.\n      operationId: GetTextOperationResult\n      parameters:\n        - description: Id of the text operation returned in the response of the 'Recognize\n            Handwritten Text'\n          in: path\n          name: operationId\n          required: true\n          schema:\n            type: string\n          examples:\n            Successful Domain Model analysis request:\n              value: 49a36324-fc4b-4387-aa06-090cfbf0064f\n      responses:\n        \"200\":\n          description: Returns the operation status.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TextOperationResult\"\n              examples:\n                Successful Domain Model analysis request:\n                  $ref: \"#/components/examples/Successful_Domain_Model_analysis_req\\\n                    uest\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\nx-ms-paths:\n  /analyze?overload=stream:\n    post:\n      description: This operation extracts a rich set of visual features based on the image\n        content.\n      operationId: AnalyzeImageInStream\n      parameters:\n        - $ref: \"#/components/parameters/VisualFeatures\"\n        - description: A string indicating which domain-specific details to return.\n            Multiple values should be comma-separated. Valid visual feature\n            types include:Celebrities - identifies celebrities if detected in\n            the image.\n          in: query\n          name: details\n          required: false\n          schema:\n            type: string\n            enum:\n              - Celebrities\n              - Landmarks\n          examples:\n            Successful Analyze with Url request:\n              value: Celebrities\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: The response include the extracted features in JSON format. Here is\n            the definitions for enumeration types clipart = 0, ambiguous = 1,\n            normal-clipart = 2, good-clipart = 3. Non-LineDrawing =\n            0,LineDrawing = 1.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ImageAnalysis\"\n              examples:\n                Successful Analyze with Url request:\n                  $ref: \"#/components/examples/Successful_Analyze_with_Url_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /describe?overload=stream:\n    post:\n      description: This operation generates a description of an image in human readable\n        language with complete sentences.  The description is based on a\n        collection of content tags, which are also returned by the operation.\n        More than one description can be generated for each image.  Descriptions\n        are ordered by their confidence score. All descriptions are in English.\n        Two input methods are supported -- (1) Uploading an image or (2)\n        specifying an image URL.A successful response will be returned in\n        JSON.  If the request failed, the response will contain an error code\n        and a message to help understand what went wrong.\n      operationId: DescribeImageInStream\n      parameters:\n        - description: Maximum number of candidate descriptions to be returned.  The\n            default is 1.\n          in: query\n          name: maxCandidates\n          required: false\n          schema:\n            type: string\n            default: \"1\"\n          examples:\n            Successful Describe request:\n              value: \"1\"\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: Image description object.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ImageDescription\"\n              examples:\n                Successful Describe request:\n                  $ref: \"#/components/examples/Successful_Describe_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /generateThumbnail?overload=stream:\n    post:\n      description: This operation generates a thumbnail image with the user-specified width\n        and height. By default, the service analyzes the image, identifies the\n        region of interest (ROI), and generates smart cropping coordinates based\n        on the ROI. Smart cropping helps when you specify an aspect ratio that\n        differs from that of the input image. A successful response contains the\n        thumbnail image binary. If the request failed, the response contains an\n        error code and a message to help determine what went wrong.\n      operationId: GenerateThumbnailInStream\n      parameters:\n        - description: Width of the thumbnail. It must be between 1 and 1024. Recommended\n            minimum of 50.\n          in: query\n          name: width\n          required: true\n          schema:\n            type: integer\n            minimum: 1\n            maximum: 1023\n          examples:\n            Successful Generate Thumbnail request:\n              value: \"500\"\n        - description: Height of the thumbnail. It must be between 1 and 1024. Recommended\n            minimum of 50.\n          in: query\n          name: height\n          required: true\n          schema:\n            type: integer\n            minimum: 1\n            maximum: 1023\n          examples:\n            Successful Generate Thumbnail request:\n              value: \"500\"\n        - description: Boolean flag for enabling smart cropping.\n          in: query\n          name: smartCropping\n          required: false\n          schema:\n            type: boolean\n            default: false\n          examples:\n            Successful Generate Thumbnail request:\n              value: true\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: The generated thumbnail in binary format.\n          content:\n            application/octet-stream:\n              schema:\n                type: string\n                format: binary\n              examples:\n                Successful Generate Thumbnail request:\n                  $ref: \"#/components/examples/Successful_Generate_Thumbnail_request\"\n        default:\n          description: Error response.\n          content:\n            application/octet-stream:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  \"/models/{model}/analyze?overload=stream\":\n    post:\n      description: \"This operation recognizes content within an image by applying a\n        domain-specific model.  The list of domain-specific models that are\n        supported by the Computer Vision API can be retrieved using the /models\n        GET request.  Currently, the API only provides a single domain-specific\n        model: celebrities. Two input methods are supported -- (1) Uploading an\n        image or (2) specifying an image URL. A successful response will be\n        returned in JSON.  If the request failed, the response will contain an\n        error code and a message to help understand what went wrong.\"\n      operationId: AnalyzeImageByDomainInStream\n      parameters:\n        - description: The domain-specific content to recognize.\n          in: path\n          name: model\n          required: true\n          schema:\n            type: string\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: Analysis result based on the domain model\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DomainModelResults\"\n              examples:\n                Successful Domain Model analysis request:\n                  $ref: \"#/components/examples/Successful_Domain_Model_analysis_req\\\n                    uest\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /ocr?overload=stream:\n    post:\n      description: Optical Character Recognition (OCR) detects printed text in an image and\n        extracts the recognized characters into a machine-usable character\n        stream.   Upon success, the OCR results will be returned. Upon failure,\n        the error code together with an error message will be returned. The\n        error code can be one of InvalidImageUrl, InvalidImageFormat,\n        InvalidImageSize, NotSupportedImage,  NotSupportedLanguage, or\n        InternalServerError.\n      operationId: RecognizePrintedTextInStream\n      parameters:\n        - $ref: \"#/components/parameters/OcrLanguage\"\n        - $ref: \"#/components/parameters/DetectOrientation\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: The OCR results in the hierarchy of region/line/word. The results\n            include text, bounding box for regions, lines and words. The angle,\n            in degrees, of the detected text with respect to the closest\n            horizontal or vertical direction. After rotating the input image\n            clockwise by this angle, the recognized text lines become horizontal\n            or vertical. In combination with the orientation property it can be\n            used to overlay recognition results correctly on the original image,\n            by rotating either the original image or recognition results by a\n            suitable angle around the center of the original image. If the angle\n            cannot be confidently detected, this property is not present. If the\n            image contains text at different angles, only part of the text will\n            be recognized correctly.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/OcrResult\"\n              examples:\n                Successful Ocr request:\n                  $ref: \"#/components/examples/Successful_Ocr_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /recognizeText?overload=stream:\n    post:\n      description: Recognize Text operation. When you use the Recognize Text interface, the\n        response contains a field called 'Operation-Location'. The\n        'Operation-Location' field contains the URL that you must use for your\n        Get Handwritten Text Operation Result operation.\n      operationId: RecognizeTextInStream\n      parameters:\n        - $ref: \"#/components/parameters/HandwritingBoolean\"\n      requestBody:\n        content:\n          application/octet-stream:\n            schema:\n              format: file\n              type: object\n        description: An image stream.\n        required: true\n        x-ms-parameter-location: method\n      responses:\n        \"202\":\n          description: The service has accepted the request and will start processing later.\n          headers:\n            Operation-Location:\n              description: \"URL to query for status of the operation. The operation ID will\n                expire in 48 hours. \"\n              schema:\n                type: string\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\n  /tag?overload=stream:\n    post:\n      description: This operation generates a list of words, or tags, that are relevant to\n        the content of the supplied image. The Computer Vision API can return\n        tags based on objects, living beings, scenery or actions found in\n        images. Unlike categories, tags are not organized according to a\n        hierarchical classification system, but correspond to image content.\n        Tags may contain hints to avoid ambiguity or provide context, for\n        example the tag 'cello' may be accompanied by the hint 'musical\n        instrument'. All tags are in English.\n      operationId: TagImageInStream\n      parameters:\n        - $ref: \"#/components/parameters/ServiceLanguage\"\n      requestBody:\n        $ref: \"#/components/requestBodies/AnalyzeImageInStreamImage\"\n      responses:\n        \"200\":\n          description: Image tags object.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TagResult\"\n              examples:\n                Successful Tag request:\n                  $ref: \"#/components/examples/Successful_Tag_request\"\n        default:\n          description: Error response.\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ComputerVisionError\"\nservers:\n  - url: https://azure.local/vision/v1.0\n  - url: https://{AzureRegion}.api.cognitive.microsoft.com/vision/v1.0\n    variables:\n      AzureRegion:\n        description: Supported Azure regions for Cognitive Services endpoints\n        enum:\n          - westus\n          - westeurope\n          - southeastasia\n          - eastus2\n          - westcentralus\n          - westus2\n          - eastus\n          - southcentralus\n          - northeurope\n          - eastasia\n          - australiaeast\n          - brazilsouth\n          - canadacentral\n          - centralindia\n          - uksouth\n          - japaneast\n        x-ms-enum:\n          modelAsString: false\n          name: AzureRegions\n        x-ms-parameter-location: client\n        x-ms-skip-url-encoding: true\n        default: westus\ncomponents:\n  examples:\n    Successful_Analyze_with_Url_request:\n      value:\n        adult:\n          adultScore: 0.0934349000453949\n          isAdultContent: false\n          isRacyContent: false\n          racyScore: 0.06861349195241928\n        categories:\n          - name: abstract_\n            score: 0.00390625\n          - detail:\n              celebrities:\n                - confidence: 0.999028444\n                  faceRectangle:\n                    height: 248\n                    left: 597\n                    top: 162\n                    width: 248\n                  name: Satya Nadella\n              landmarks:\n                - confidence: 0.9978346\n                  name: Forbidden City\n            name: people_\n            score: 0.83984375\n        color:\n          accentColor: 873B59\n          dominantColorBackground: Brown\n          dominantColorForeground: Brown\n          dominantColors:\n            - Brown\n            - Black\n          isBWImg: false\n        description:\n          captions:\n            - confidence: 0.48293603002174407\n              text: Satya Nadella sitting on a bench\n          tags:\n            - person\n            - man\n            - outdoor\n            - window\n            - glasses\n        faces:\n          - age: 44\n            faceRectangle:\n              height: 250\n              left: 593\n              top: 160\n              width: 250\n            gender: Male\n        imageType:\n          clipArtType: 0\n          lineDrawingType: 0\n        metadata:\n          format: Jpeg\n          height: 1000\n          width: 1500\n        requestId: 0dbec5ad-a3d3-4f7e-96b4-dfd57efe967d\n        tags:\n          - confidence: 0.9897908568382263\n            name: person\n          - confidence: 0.9449388980865479\n            name: man\n          - confidence: 0.938492476940155\n            name: outdoor\n          - confidence: 0.8951393961906433\n            name: window\n    Successful_Describe_request:\n      value:\n        description:\n          captions:\n            - confidence: 0.48293603002174407\n              text: Satya Nadella sitting on a bench\n            - confidence: 0.4003700681542283\n              text: Satya Nadella is sitting on a bench\n            - confidence: 0.38035155997373377\n              text: Satya Nadella sitting in front of a building\n          tags:\n            - person\n            - man\n            - outdoor\n            - window\n            - glasses\n        metadata:\n          format: Jpeg\n          height: 1000\n          width: 1500\n        requestId: ed2de1c6-fb55-4686-b0da-4da6e05d283f\n    Successful_Generate_Thumbnail_request:\n      value: \"{Binary}\"\n    Successful_List_Domains_request:\n      value:\n        models:\n          - categories:\n              - people_\n            name: celebrities\n          - categories:\n              - building_\n            name: landmarks\n    Successful_Domain_Model_analysis_request:\n      value:\n        metadata:\n          format: Jpeg\n          height: 1000\n          width: 1500\n        requestId: f0027b4b-dc0d-4082-9228-1545ed246b03\n        result:\n          celebrities:\n            - confidence: 0.999028444\n              faceRectangle:\n                height: 248\n                left: 597\n                top: 162\n                width: 248\n              name: Satya Nadella\n    Successful_Ocr_request:\n      value:\n        language: en\n        orientation: Up\n        regions:\n          - boundingBox: 462,379,497,258\n            lines:\n              - boundingBox: 462,379,497,74\n                words:\n                  - boundingBox: 462,379,41,73\n                    text: A\n                  - boundingBox: 523,379,153,73\n                    text: GOAL\n                  - boundingBox: 694,379,265,74\n                    text: WITHOUT\n              - boundingBox: 565,471,289,74\n                words:\n                  - boundingBox: 565,471,41,73\n                    text: A\n                  - boundingBox: 626,471,150,73\n                    text: PLAN\n                  - boundingBox: 801,472,53,73\n                    text: IS\n              - boundingBox: 519,563,375,74\n                words:\n                  - boundingBox: 519,563,149,74\n                    text: JUST\n                  - boundingBox: 683,564,41,72\n                    text: A\n                  - boundingBox: 741,564,153,73\n                    text: WISH\n        textAngle: -2.0000000000000338\n    Successful_Tag_request:\n      value:\n        metadata:\n          format: Jpeg\n          height: 400\n          width: 400\n        requestId: 1ad0e45e-b7b4-4be3-8042-53be96103337\n        tags:\n          - confidence: 0.9999997615814209\n            name: grass\n          - confidence: 0.9999706745147705\n            name: outdoor\n          - confidence: 0.9992897510528564\n            name: sky\n          - confidence: 0.9964632391929626\n            name: building\n          - confidence: 0.9927980303764343\n            name: house\n          - confidence: 0.8226802945137024\n            name: lawn\n          - confidence: 0.6412225365638733\n            name: green\n          - confidence: 0.31403225660324097\n            name: residential\n  parameters:\n    DetectOrientation:\n      description: \"Whether detect the text orientation in the image. With\n        detectOrientation=true the OCR service tries to detect the image\n        orientation and correct it before further processing (e.g. if it's\n        upside-down). \"\n      in: query\n      name: detectOrientation\n      required: true\n      x-ms-parameter-location: method\n      schema:\n        type: boolean\n        default: true\n      examples:\n        Successful Ocr request:\n          value: \"true\"\n    HandwritingBoolean:\n      description: If 'true' is specified, handwriting recognition is performed. If this\n        parameter is set to 'false' or is not specified, printed text\n        recognition is performed.\n      in: query\n      name: detectHandwriting\n      required: false\n      x-ms-parameter-location: method\n      schema:\n        type: boolean\n        default: false\n    OcrLanguage:\n      description: The BCP-47 language code of the text to be detected in the image. The\n        default value is 'unk'\n      in: query\n      name: language\n      required: false\n      x-ms-enum:\n        modelAsString: false\n        name: OcrLanguages\n      x-ms-parameter-location: method\n      x-nullable: false\n      schema:\n        type: string\n        enum:\n          - unk\n          - zh-Hans\n          - zh-Hant\n          - cs\n          - da\n          - nl\n          - en\n          - fi\n          - fr\n          - de\n          - el\n          - hu\n          - it\n          - ja\n          - ko\n          - nb\n          - pl\n          - pt\n          - ru\n          - es\n          - sv\n          - tr\n          - ar\n          - ro\n          - sr-Cyrl\n          - sr-Latn\n          - sk\n        default: unk\n      examples:\n        Successful Ocr request:\n          value: en\n    ServiceLanguage:\n      description: The desired language for output generation. If this parameter is not\n        specified, the default value is \u0026quot;en\u0026quot;.Supported languages:en -\n        English, Default. es - Spanish, ja - Japanese, pt - Portuguese, zh -\n        Simplified Chinese.\n      in: query\n      name: language\n      required: false\n      x-ms-parameter-location: method\n      x-nullable: false\n      schema:\n        type: string\n        enum:\n          - en\n          - es\n          - ja\n          - pt\n          - zh\n        default: en\n      examples:\n        Successful Analyze with Url request:\n          value: en\n    VisualFeatures:\n      description: A string indicating what visual feature types to return. Multiple values\n        should be comma-separated. Valid visual feature types include:Categories\n        - categorizes image content according to a taxonomy defined in\n        documentation. Tags - tags the image with a detailed list of words\n        related to the image content. Description - describes the image content\n        with a complete English sentence. Faces - detects if faces are present.\n        If present, generate coordinates, gender and age. ImageType - detects if\n        image is clipart or a line drawing. Color - determines the accent color,\n        dominant color, and whether an image is black\u0026white.Adult - detects if\n        the image is pornographic in nature (depicts nudity or a sex\n        act).  Sexually suggestive content is also detected.\n      in: query\n      name: visualFeatures\n      required: false\n      x-ms-parameter-location: method\n      style: form\n      explode: false\n      schema:\n        type: array\n        items:\n          enum:\n            - ImageType\n            - Faces\n            - Adult\n            - Categories\n            - Color\n            - Tags\n            - Description\n          type: string\n          x-ms-enum:\n            modelAsString: false\n            name: VisualFeatureTypes\n          nullable: false\n      examples:\n        Successful Analyze with Url request:\n          value: Categories,Adult,Tags,Description,Faces,Color,ImageType\n  requestBodies:\n    AnalyzeImageInStreamImage:\n      content:\n        application/octet-stream:\n          schema:\n            format: file\n            type: object\n        multipart/form-data:\n          schema:\n            format: file\n            type: object\n      description: An image stream.\n      required: true\n      x-ms-parameter-location: method\n    AnalyzeImageImageurl:\n      content:\n        application/json:\n          schema:\n            properties:\n              url:\n                description: Publicly reachable URL of an image\n                type: string\n            required:\n              - url\n            type: object\n      description: A JSON document with a URL pointing to the image that is to be analyzed.\n      required: true\n      x-ms-client-flatten: true\n      x-ms-parameter-location: method\n  securitySchemes:\n    apim_key:\n      in: header\n      name: Ocp-Apim-Subscription-Key\n      type: apiKey\n  schemas:\n    AdultInfo:\n      description: An object describing whether the image contains adult-oriented content\n        and/or is racy.\n      properties:\n        adultScore:\n          description: Score from 0 to 1 that indicates how much of adult content is within\n            the image.\n          format: double\n          type: number\n          nullable: false\n        isAdultContent:\n          description: A value indicating if the image contains adult-oriented content.\n          type: boolean\n          nullable: false\n        isRacyContent:\n          description: A value indicating if the image is race.\n          type: boolean\n          nullable: false\n        racyScore:\n          description: Score from 0 to 1 that indicates how suggestive is the image.\n          format: double\n          type: number\n          nullable: false\n      type: object\n    BoundingBox:\n      items:\n        type: integer\n        nullable: false\n      type: array\n    Category:\n      description: An object describing identified category.\n      properties:\n        detail:\n          $ref: \"#/components/schemas/CategoryDetail\"\n        name:\n          description: Name of the category.\n          type: string\n        score:\n          description: Scoring of the category.\n          format: double\n          type: number\n      type: object\n    CategoryDetail:\n      description: An object describing additional category details.\n      properties:\n        celebrities:\n          description: An array of celebrities if any identified.\n          items:\n            $ref: \"#/components/schemas/CelebritiesModel\"\n          type: array\n      type: object\n    CelebritiesModel:\n      description: An object describing possible celebrity identification.\n      properties:\n        confidence:\n          description: Level of confidence ranging from 0 to 1.\n          format: double\n          type: number\n        faceRectangle:\n          $ref: \"#/components/schemas/FaceRectangle\"\n        name:\n          description: Name of the celebrity.\n          type: string\n      type: object\n    CelebrityResults:\n      description: List of celebrities recognized in the image.\n      properties:\n        celebrities:\n          items:\n            $ref: \"#/components/schemas/CelebritiesModel\"\n          type: array\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the REST API request.\n          type: string\n      type: object\n    ColorInfo:\n      description: An object providing additional metadata describing color attributes.\n      properties:\n        accentColor:\n          description: Possible accent color.\n          type: string\n        dominantColorBackground:\n          description: Possible dominant background color.\n          type: string\n        dominantColorForeground:\n          description: Possible dominant foreground color.\n          type: string\n        dominantColors:\n          description: An array of possible dominant colors.\n          items:\n            type: string\n          type: array\n        isBWImg:\n          description: A value indicating if the image is black and white.\n          type: boolean\n      type: object\n    ComputerVisionError:\n      properties:\n        code:\n          description: The error code.\n          enum:\n            - InvalidImageUrl\n            - InvalidImageFormat\n            - InvalidImageSize\n            - NotSupportedVisualFeature\n            - NotSupportedImage\n            - InvalidDetails\n            - NotSupportedLanguage\n            - BadArgument\n            - FailedToProcess\n            - Timeout\n            - InternalServerError\n            - Unspecified\n            - StorageException\n          type: string\n          x-ms-enum:\n            modelAsString: false\n            name: ComputerVisionErrorCodes\n        message:\n          description: A message explaining the error reported by the service.\n          type: string\n        requestId:\n          description: A unique request identifier.\n          type: string\n      required:\n        - code\n        - message\n      type: object\n    DomainModelResults:\n      description: Result of image analysis using a specific domain model including\n        additional metadata.\n      properties:\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the REST API request.\n          type: string\n        result:\n          description: Model-specific response\n          type: object\n          x-ms-client-flatten: true\n      type: object\n    FaceDescription:\n      description: An object describing a face identified in the image.\n      properties:\n        age:\n          description: Possible age of the face.\n          type: integer\n        faceRectangle:\n          $ref: \"#/components/schemas/FaceRectangle\"\n        gender:\n          description: Possible gender of the face.\n          enum:\n            - Male\n            - Female\n          type: string\n          x-ms-enum:\n            modelAsString: false\n            name: Gender-\n      type: object\n    FaceRectangle:\n      description: An object describing face rectangle.\n      properties:\n        height:\n          description: Height measured from the top-left point of the face.\n          type: integer\n        left:\n          description: X-coordinate of the top left point of the face.\n          type: integer\n        top:\n          description: Y-coordinate of the top left point of the face.\n          type: integer\n        width:\n          description: Width measured from the top-left point of the face.\n          type: integer\n      type: object\n    ImageAnalysis:\n      description: Result of AnalyzeImage operation.\n      properties:\n        adult:\n          $ref: \"#/components/schemas/AdultInfo\"\n        categories:\n          description: An array indicating identified categories.\n          items:\n            $ref: \"#/components/schemas/Category\"\n          type: array\n        color:\n          $ref: \"#/components/schemas/ColorInfo\"\n        description:\n          $ref: \"#/components/schemas/ImageDescriptionDetails\"\n        faces:\n          description: An array of possible faces within the image.\n          items:\n            $ref: \"#/components/schemas/FaceDescription\"\n          type: array\n        imageType:\n          $ref: \"#/components/schemas/ImageType\"\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the request for tracking purposes.\n          type: string\n        tags:\n          description: A list of tags with confidence level.\n          items:\n            $ref: \"#/components/schemas/ImageTag\"\n          type: array\n      type: object\n    ImageCaption:\n      description: An image caption, i.e. a brief description of what the image depicts.\n      properties:\n        confidence:\n          description: The level of confidence the service has in the caption\n          format: double\n          type: number\n        text:\n          description: The text of the caption\n          type: string\n      type: object\n    ImageDescription:\n      description: A collection of content tags, along with a list of captions sorted by\n        confidence level, and image metadata.\n      properties:\n        description:\n          $ref: \"#/components/schemas/ImageDescriptionDetails\"\n      type: object\n    ImageDescriptionDetails:\n      description: A collection of content tags, along with a list of captions sorted by\n        confidence level, and image metadata.\n      properties:\n        captions:\n          description: A list of captions, sorted by confidence level.\n          items:\n            $ref: \"#/components/schemas/ImageCaption\"\n          type: array\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the REST API request.\n          type: string\n        tags:\n          description: A collection of image tags.\n          items:\n            type: string\n          type: array\n      type: object\n    ImageMetadata:\n      description: Image metadata\n      properties:\n        format:\n          description: Image format\n          type: string\n        height:\n          description: Image height\n          format: int32\n          type: integer\n        width:\n          description: Image width\n          format: int32\n          type: integer\n      type: object\n    ImageTag:\n      description: An image caption, i.e. a brief description of what the image depicts.\n      properties:\n        confidence:\n          description: The level of confidence the service has in the caption\n          format: double\n          type: number\n        name:\n          description: The tag value\n          type: string\n      type: object\n    ImageType:\n      description: An object providing possible image types and matching confidence levels.\n      properties:\n        clipArtType:\n          description: Confidence level that the image is a clip art.\n          type: number\n        lineDrawingType:\n          description: Confidence level that the image is a line drawing.\n          type: number\n      type: object\n    LandmarkResults:\n      description: List of landmarks recognized in the image.\n      properties:\n        landmarks:\n          items:\n            description: A landmark recognized in the image\n            properties:\n              confidence:\n                description: Confidence level for the landmark recognition.\n                format: double\n                type: number\n              name:\n                description: Name of the landmark.\n                type: string\n            type: object\n          type: array\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the REST API request.\n          type: string\n      type: object\n    Line:\n      properties:\n        boundingBox:\n          $ref: \"#/components/schemas/BoundingBox\"\n        text:\n          type: string\n        words:\n          items:\n            $ref: \"#/components/schemas/Word\"\n          type: array\n      type: object\n    ListModelsResult:\n      description: Result of the List Domain Models operation.\n      properties:\n        models:\n          description: An array of supported models.\n          items:\n            $ref: \"#/components/schemas/ModelDescription\"\n          readOnly: true\n          type: array\n      type: object\n    ModelDescription:\n      description: An object describing supported model by name and categories.\n      properties:\n        categories:\n          items:\n            type: string\n          type: array\n        name:\n          type: string\n      type: object\n    OcrLine:\n      description: An object describing a single recognized line of text.\n      properties:\n        boundingBox:\n          description: Bounding box of a recognized line. The four integers represent the\n            x-coordinate of the left edge, the y-coordinate of the top edge,\n            width, and height of the bounding box, in the coordinate system of\n            the input image, after it has been rotated around its center\n            according to the detected text angle (see textAngle property), with\n            the origin at the top-left corner, and the y-axis pointing down.\n          type: string\n        words:\n          description: An array of objects, where each object represents a recognized word.\n          items:\n            $ref: \"#/components/schemas/OcrWord\"\n          type: array\n      type: object\n    OcrRegion:\n      description: A region consists of multiple lines (e.g. a column of text in a\n        multi-column document).\n      properties:\n        boundingBox:\n          description: Bounding box of a recognized region. The four integers represent the\n            x-coordinate of the left edge, the y-coordinate of the top edge,\n            width, and height of the bounding box, in the coordinate system of\n            the input image, after it has been rotated around its center\n            according to the detected text angle (see textAngle property), with\n            the origin at the top-left corner, and the y-axis pointing down.\n          type: string\n        lines:\n          items:\n            $ref: \"#/components/schemas/OcrLine\"\n          type: array\n      type: object\n    OcrResult:\n      properties:\n        language:\n          description: The BCP-47 language code of the text in the image.\n          type: string\n        orientation:\n          description: Orientation of the text recognized in the image. The value\n            (up,down,left, or right) refers to the direction that the top of the\n            recognized text is facing, after the image has been rotated around\n            its center according to the detected text angle (see textAngle\n            property).\n          type: string\n        regions:\n          description: An array of objects, where each object represents a region of\n            recognized text.\n          items:\n            $ref: \"#/components/schemas/OcrRegion\"\n          type: array\n        textAngle:\n          description: The angle, in degrees, of the detected text with respect to the\n            closest horizontal or vertical direction. After rotating the input\n            image clockwise by this angle, the recognized text lines become\n            horizontal or vertical. In combination with the orientation property\n            it can be used to overlay recognition results correctly on the\n            original image, by rotating either the original image or recognition\n            results by a suitable angle around the center of the original image.\n            If the angle cannot be confidently detected, this property is not\n            present. If the image contains text at different angles, only part\n            of the text will be recognized correctly.\n          format: double\n          type: number\n      type: object\n    OcrWord:\n      description: Information on a recognized word.\n      properties:\n        boundingBox:\n          description: Bounding box of a recognized word. The four integers represent the\n            x-coordinate of the left edge, the y-coordinate of the top edge,\n            width, and height of the bounding box, in the coordinate system of\n            the input image, after it has been rotated around its center\n            according to the detected text angle (see textAngle property), with\n            the origin at the top-left corner, and the y-axis pointing down.\n          type: string\n        text:\n          description: String value of a recognized word.\n          type: string\n      type: object\n    RecognitionResult:\n      properties:\n        lines:\n          items:\n            $ref: \"#/components/schemas/Line\"\n          type: array\n      type: object\n    ServiceLanguage:\n      type: string\n    TagResult:\n      description: The results of a image tag operation, including any tags and image\n        metadata.\n      properties:\n        metadata:\n          $ref: \"#/components/schemas/ImageMetadata\"\n        requestId:\n          description: Id of the REST API request.\n          type: string\n        tags:\n          description: A list of tags with confidence level.\n          items:\n            $ref: \"#/components/schemas/ImageTag\"\n          type: array\n      type: object\n    TextOperationResult:\n      properties:\n        recognitionResult:\n          $ref: \"#/components/schemas/RecognitionResult\"\n        status:\n          description: Status of the text operation.\n          enum:\n            - Not Started\n            - Running\n            - Failed\n            - Succeeded\n          type: string\n          x-ms-enum:\n            modelAsString: false\n            name: TextOperationStatusCodes\n          nullable: false\n      type: object\n    Word:\n      properties:\n        boundingBox:\n          $ref: \"#/components/schemas/BoundingBox\"\n        text:\n          type: string\n      type: object\n",
			"canonicalURL": "/github.com/restful-ma/thresholds@5b0b2a3322d3b2b7c0e0f2c0c0ad0e524e67bf82/-/blob/benchmark-repository/openapi/azure.com-cognitiveservices-ComputerVision-1.0-swagger.yaml",
			"externalURLs": [
				{
					"url": "https://github.com/restful-ma/thresholds/blob/5b0b2a3322d3b2b7c0e0f2c0c0ad0e524e67bf82/benchmark-repository/openapi/azure.com-cognitiveservices-ComputerVision-1.0-swagger.yaml",
					"serviceKind": "GITHUB"
				}
			]
		}
	},
	"Error": "buildIR: make ir: path \"/generateThumbnail\": post: responses: default: contents: application/octet-stream: octet stream with \"object\" schema not supported"
}