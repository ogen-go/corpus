{
	"File": {
		"__typename": "FileMatch",
		"repository": {
			"name": "github.com/apinf/ml-rest"
		},
		"file": {
			"name": "ml-rest.yaml",
			"size": 0,
			"path": "doc/ml-rest.yaml",
			"byteSize": 20942,
			"content": "openapi: 3.0.0-RC0\nservers: []\ninfo:\n  description: \u003e-\n    This is a machine learning API, designed to allow people to interact with a\n    machine learning service over a network.\n  version: 0.1.0\n  title: Machine Learning REST\n  termsOfService: ''\n  contact:\n    email: brylie.oxley@apinf.io\n    name: Brylie Christopher Oxley\n  license:\n    name: Public Domain (Creative Commons Zero)\n    url: 'https://creativecommons.org/publicdomain/zero/1.0/'\ntags:\n  - name: Classification\n    description: Identify which group an observation belongs to.\n  - name: Regression\n    description: 'Predict values of a quantity, based on other observations.'\n  - name: Clustering\n    description: Find groups among observations.\n  - name: Dimensionality reduction\n    description: Simplify data by reducing the number of dimensions (e.g. attributes)\npaths:\n  /sklearn/svm/linear-svc:\n    summary: \u003e-\n      Linear SVC is capable of performing multi-class classification on a\n      dataset.\n    put:\n      summary: Create a new Linear SVC instance\n      description: ''\n      externalDocs:\n        url: \u003e-\n          http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n        description: \u003e-\n          Linear Support Vector Classification.\n\n\n          Similar to SVC with parameter kernel=’linear’, but implemented in\n          terms of liblinear rather than libsvm, so it has more flexibility in\n          the choice of penalties and loss functions and should scale better to\n          large numbers of samples.\n\n\n          This class supports both dense and sparse input and the multiclass\n          support is handled according to a one-vs-the-rest scheme.\n      parameters:\n        - name: C\n          in: query\n          required: false\n          schema: {}\n          description: Penalty parameter C of the error term.\n          allowEmptyValue: false\n        - name: loss\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Specifies the loss function. ‘hinge’ is the standard SVM loss (used\n            e.g. by the SVC class) while ‘squared_hinge’ is the square of the\n            hinge loss.\n        - name: penalty\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Specifies the norm used in the penalization. The ‘l2’ penalty is the\n            standard used in SVC. The ‘l1’ leads to coef_ vectors that are\n            sparse.\n        - name: dual\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Select the algorithm to either solve the dual or primal optimization\n            problem. Prefer dual=False when n_samples \u003e n_features.\n        - name: tol\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Tolerance for stopping criteria.\n        - name: multi_class\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Determines the multi-class strategy if y contains more than two\n            classes. \"ovr\" trains n_classes one-vs-rest classifiers, while\n            \"crammer_singer\" optimizes a joint objective over all classes. While\n            crammer_singer is interesting from a theoretical perspective as it\n            is consistent, it is seldom used in practice as it rarely leads to\n            better accuracy and is more expensive to compute. If\n            \"crammer_singer\" is chosen, the options loss, penalty and dual will\n            be ignored.\n        - name: fit_intercept\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Whether to calculate the intercept for this model. If set to false,\n            no intercept will be used in calculations (i.e. data is expected to\n            be already centered).\n        - name: intercept_scaling\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            When self.fit_intercept is True, instance vector x becomes [x,\n            self.intercept_scaling], i.e. a “synthetic” feature with constant\n            value equals to intercept_scaling is appended to the instance\n            vector. The intercept becomes intercept_scaling * synthetic feature\n            weight Note! the synthetic feature weight is subject to l1/l2\n            regularization as all other features. To lessen the effect of\n            regularization on synthetic feature weight (and therefore on the\n            intercept) intercept_scaling has to be increased.\n        - name: class_weight\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Set the parameter C of class i to class_weight[i]*C for SVC. If not\n            given, all classes are supposed to have weight one. The “balanced”\n            mode uses the values of y to automatically adjust weights inversely\n            proportional to class frequencies in the input data as n_samples /\n            (n_classes * np.bincount(y))\n        - name: verbose\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Enable verbose output. Note that this setting takes advantage of a\n            per-process runtime setting in liblinear that, if enabled, may not\n            work properly in a multithreaded context.\n        - name: random_state\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            The seed of the pseudo random number generator to use when shuffling\n            the data.\n        - name: max_iter\n          in: query\n          required: false\n          schema:\n            type: string\n          description: The maximum number of iterations to be run.\n      operationId: ''\n      responses:\n        default:\n          description: Default response\n      tags:\n        - Classification\n  /sklearn/linear-model/linear-regression:\n    summary: Ordinary least squares Linear Regression.\n    description: \u003e-\n      From the implementation point of view, this is just plain Ordinary Least\n      Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n    put:\n      summary: Create an instance of Linear Regression classifier.\n      description: ''\n      externalDocs:\n        url: \u003e-\n          http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n      parameters:\n        - name: fit_intercept\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            whether to calculate the intercept for this model. If set to false,\n            no intercept will be used in calculations (e.g. data is expected to\n            be already centered).\n        - name: normalize\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            If True, the regressors X will be normalized before regression. This\n            parameter is ignored when fit_intercept is set to False. When the\n            regressors are normalized, note that this makes the hyperparameters\n            learnt more robust and almost independent of the number of samples.\n            The same property is not valid for standardized data. However, if\n            you wish to standardize, please use preprocessing.StandardScaler\n            before calling fit on an estimator with normalize=False.\n        - name: copy_X\n          in: query\n          required: false\n          schema:\n            type: string\n          description: 'If True, X will be copied; else, it may be overwritten.'\n        - name: n_jobs\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            The number of jobs to use for the computation. If -1 all CPUs are\n            used. This will only provide speedup for n_targets \u003e 1 and\n            sufficient large problems.\n      operationId: ''\n      responses:\n        default:\n          description: Default response\n      tags:\n        - Regression\n  /sklearn/cluster/kmeans:\n    description: \u003e-\n      The KMeans algorithm clusters data by trying to separate samples in n\n      groups of equal variance, minimizing a criterion known as the inertia or\n      within-cluster sum-of-squares. This algorithm requires the number of\n      clusters to be specified. It scales well to large number of samples and\n      has been used across a large range of application areas in many different\n      fields.\n    summary: K-Means clustering\n    put:\n      summary: Create a KMeans classifier instance.\n      description: ''\n      externalDocs:\n        url: \u003e-\n          http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n      parameters:\n        - name: n_clusters\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            The number of clusters to form as well as the number of centroids to\n            generate.\n        - name: max_iter\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Maximum number of iterations of the k-means algorithm for a single\n            run.\n        - name: n_init\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Number of time the k-means algorithm will be run with different\n            centroid seeds. The final results will be the best output of n_init\n            consecutive runs in terms of inertia.\n        - name: init\n          in: query\n          required: false\n          schema:\n            type: string\n          description: |-\n\n\n                Method for initialization, defaults to ‘k-means++’:\n\n                ‘k-means++’ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence. See section Notes in k_init for more details.\n\n                ‘random’: choose k observations (rows) at random from data for the initial centroids.\n\n                If an ndarray is passed, it should be of shape (n_clusters, n_features) and gives the initial centers.\n        - name: algorithm\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            K-means algorithm to use. The classical EM-style algorithm is\n            “full”. The “elkan” variation is more efficient by using the\n            triangle inequality, but currently doesn’t support sparse data.\n            “auto” chooses “elkan” for dense data and “full” for sparse data.\n        - name: precompute_distances\n          in: query\n          required: false\n          schema:\n            type: string\n          description: |\n\n\n                Precompute distances (faster but takes more memory).\n\n                ‘auto’ : do not precompute distances if n_samples * n_clusters \u003e 12 million. This corresponds to about 100MB overhead per job using double precision.\n\n                True : always precompute distances\n\n                False : never precompute distances\n        - name: tol\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Relative tolerance with regards to inertia to declare convergence\n        - name: n_jobs\n          in: query\n          required: false\n          schema:\n            type: string\n          description: |\n\n\n                The number of jobs to use for the computation. This works by computing each of the n_init runs in parallel.\n\n                If -1 all CPUs are used. If 1 is given, no parallel computing code is used at all, which is useful for debugging. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one are used.\n        - name: random_state\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            The generator used to initialize the centers. If an integer is\n            given, it fixes the seed. Defaults to the global numpy random number\n            generator.\n        - name: verbose\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Verbosity mode.\n        - name: copy_x\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            When pre-computing distances it is more numerically accurate to\n            center the data first. If copy_x is True, then the original data is\n            not modified. If False, the original data is modified, and put back\n            before the function returns, but small numerical differences may be\n            introduced by subtracting and then adding the data mean.\n      operationId: ''\n      responses:\n        default:\n          description: Default response\n      tags:\n        - Clustering\n  /sklearn/decomposition/pca:\n    summary: Principal component analysis (PCA)\n    description: \u003e-\n      Linear dimensionality reduction using Singular Value Decomposition of the\n      data to project it to a lower dimensional space.\n\n\n      It uses the LAPACK implementation of the full SVD or a randomized\n      truncated SVD by the method of Halko et al. 2009, depending on the shape\n      of the input data and the number of components to extract.\n\n\n      It can also use the scipy.sparse.linalg ARPACK implementation of the\n      truncated SVD.\n\n\n      Notice that this class does not support sparse input. See TruncatedSVD for\n      an alternative with sparse data.\n    put:\n      summary: Create a Principle Component Analysis instance.\n      description: ''\n      externalDocs:\n        url: \u003e-\n          http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n      parameters:\n        - name: n_components\n          in: query\n          required: false\n          schema:\n            type: string\n          description: |\n\n\n                Number of components to keep. if n_components is not set all components are kept:\n\n                n_components == min(n_samples, n_features)\n\n                if n_components == ‘mle’ and svd_solver == ‘full’, Minka’s MLE is used to guess the dimension if 0 \u003c n_components \u003c 1 and svd_solver == ‘full’, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components n_components cannot be equal to n_features for svd_solver == ‘arpack’.\n        - name: copy\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            If False, data passed to fit are overwritten and running\n            fit(X).transform(X) will not yield the expected results, use\n            fit_transform(X) instead.\n        - name: whiten\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            When True (False by default) the components_ vectors are multiplied\n            by the square root of n_samples and then divided by the singular\n            values to ensure uncorrelated outputs with unit component-wise\n            variances.\n\n\n            Whitening will remove some information from the transformed signal\n            (the relative variance scales of the components) but can sometime\n            improve the predictive accuracy of the downstream estimators by\n            making their data respect some hard-wired assumptions.\n        - name: svd_solver\n          in: query\n          required: false\n          schema:\n            type: string\n          description: |-\n\n            auto :\n\n                the solver is selected by a default policy based on X.shape and n_components: if the input data is larger than 500x500 and the number of components to extract is lower than 80% of the smallest dimension of the data, then the more efficient ‘randomized’ method is enabled. Otherwise the exact full SVD is computed and optionally truncated afterwards.\n            full :\n\n                run exact full SVD calling the standard LAPACK solver via scipy.linalg.svd and select the components by postprocessing\n            arpack :\n\n                run SVD truncated to n_components calling ARPACK solver via scipy.sparse.linalg.svds. It requires strictly 0 \u003c n_components \u003c X.shape[1]\n            randomized :\n\n                run randomized SVD by the method of Halko et al.\n        - name: tol\n          in: query\n          required: false\n          schema:\n            type: string\n          description: Tolerance for singular values computed by svd_solver == ‘arpack’.\n        - name: iterated_power\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Number of iterations for the power method computed by svd_solver ==\n            ‘randomized’.\n        - name: random_state\n          in: query\n          required: false\n          schema:\n            type: string\n          description: \u003e-\n            Pseudo Random Number generator seed control. If None, use the\n            numpy.random singleton. Used by svd_solver == ‘arpack’ or\n            ‘randomized’.\n      operationId: ''\n      responses:\n        default:\n          description: Default response\n      tags:\n        - Dimensionality reduction\ncomponents:\n  schemas:\n    Order:\n      type: object\n      properties:\n        id:\n          type: integer\n          format: int64\n        petId:\n          type: integer\n          format: int64\n        quantity:\n          type: integer\n          format: int32\n        shipDate:\n          type: string\n          format: date-time\n        status:\n          type: string\n          description: Order Status\n          enum:\n            - placed\n            - approved\n            - delivered\n        complete:\n          type: boolean\n          default: false\n      xml:\n        name: Order\n    Category:\n      type: object\n      properties:\n        id:\n          type: integer\n          format: int64\n        name:\n          type: string\n      xml:\n        name: Category\n    User:\n      type: object\n      properties:\n        id:\n          type: integer\n          format: int64\n        username:\n          type: string\n        firstName:\n          type: string\n        lastName:\n          type: string\n        email:\n          type: string\n        password:\n          type: string\n        phone:\n          type: string\n        userStatus:\n          type: integer\n          format: int32\n          description: User Status\n      xml:\n        name: User\n    Tag:\n      type: object\n      properties:\n        id:\n          type: integer\n          format: int64\n        name:\n          type: string\n      xml:\n        name: Tag\n    Pet:\n      type: object\n      required:\n        - name\n        - photoUrls\n      properties:\n        id:\n          type: integer\n          format: int64\n        category:\n          $ref: '#/components/schemas/Category'\n        name:\n          type: string\n          example: doggie\n        photoUrls:\n          type: array\n          xml:\n            name: photoUrl\n            wrapped: true\n          items:\n            type: string\n        tags:\n          type: array\n          xml:\n            name: tag\n            wrapped: true\n          items:\n            $ref: '#/components/schemas/Tag'\n        status:\n          type: string\n          description: pet status in the store\n          enum:\n            - available\n            - pending\n            - sold\n      xml:\n        name: Pet\n    ApiResponse:\n      type: object\n      properties:\n        code:\n          type: integer\n          format: int32\n        type:\n          type: string\n        message:\n          type: string\n  responses: {}\n  parameters: {}\n  examples: {}\n  requestBodies:\n    requestBody1:\n      content:\n        application/json:\n          description: Pet object that needs to be added to the store\n          schema:\n            $ref: '#/components/schemas/Pet'\n        application/xml:\n          description: Pet object that needs to be added to the store\n          schema:\n            $ref: '#/components/schemas/Pet'\n    requestBody2:\n      content:\n        application/json:\n          description: List of user object\n          schema:\n            type: array\n            items:\n              $ref: '#/components/schemas/User'\n  securitySchemes: {}\n  headers: {}\n  links: {}\n  callbacks: {}\nsecurity: []\n",
			"canonicalURL": "/github.com/apinf/ml-rest@cbffd301a23ddc2ea7d17285d2d17c512f37b3c4/-/blob/doc/ml-rest.yaml",
			"externalURLs": [
				{
					"url": "https://github.com/apinf/ml-rest/blob/cbffd301a23ddc2ea7d17285d2d17c512f37b3c4/doc/ml-rest.yaml",
					"serviceKind": "GITHUB"
				}
			]
		}
	},
	"Error": "parse: parse spec: parse version: at doc/ml-rest.yaml:1:10: invalid version: invalid patch version: strconv.Atoi: parsing \"0-RC0\": invalid syntax"
}