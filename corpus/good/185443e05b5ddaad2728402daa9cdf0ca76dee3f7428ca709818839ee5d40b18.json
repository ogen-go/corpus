{
	"File": {
		"__typename": "FileMatch",
		"repository": {
			"name": "github.com/APIs-guru/openapi-directory"
		},
		"file": {
			"name": "openapi.yaml",
			"size": 0,
			"path": "APIs/salesforce.local/einstein/2.0.1/openapi.yaml",
			"byteSize": 77681,
			"content": "openapi: 3.0.1\nservers:\n  - url: http://salesforce.local\ninfo:\n  description: Provided by [Salesforce](https://www.einstein-hub.com/)  � Copyright 2000�2020 salesforce.com, inc. All rights reserved. Salesforce is a registered trademark of salesforce.com, inc., as are other names and marks. Other marks appearing herein may be trademarks of their respective owners. **Last updated:** Aug 17, 2020\n  title: Einstein Vision and Einstein Language\n  version: 2.0.1\n  x-apisguru-categories:\n    - text\n  x-origin:\n    - format: openapi\n      url: https://raw.githubusercontent.com/MetaMind/openapi/master/vision-language-api-openapi-2.0.1.yaml\n      version: \"3.0\"\n  x-providerName: salesforce.local\n  x-serviceName: einstein\nexternalDocs:\n  description: For more information, see the Einstein Platform Services Developer Guide\n  url: https://metamind.readme.io\ntags:\n  - description: Resources that let you get API usage information.\n    name: Check API Usage\n  - description: Resources that manage authorization tokens.\n    name: Authorization\n  - description: Resources that manage image datasets.\n    name: Vision Datasets\n  - description: Resources that manage image examples.\n    name: Vision Examples\n  - description: Resources that handle image dataset training.\n    name: Vision Training\n  - description: Resources that manage image models and model metrics.\n    name: Vision Models\n  - description: Resources that return predictions for image input.\n    name: Vision Prediction\n  - description: Resources that manage text datasets.\n    name: Language Datasets\n  - description: Resources that manage text examples.\n    name: Language Examples\n  - description: Resources that handle text dataset training.\n    name: Language Training\n  - description: Resources that manage text models and model metrics.\n    name: Language Models\n  - description: Resources that return predictions for text input.\n    name: Language Prediction\npaths:\n  /v2/apiusage:\n    get:\n      description: Returns prediction usage on a monthly basis for the current calendar month and future months. Each apiusage object in the response corresponds to a calendar month in your plan.\n      operationId: getApiUsagePlansV2\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ApiUsageList\"\n          description: api usage\n      security:\n        - bearer_token: []\n      summary: Get API Isage\n      tags:\n        - Check API Usage\n  /v2/language/datasets:\n    get:\n      description: Returns a list of datasets and their labels that were created by the current user. The response is sorted by dataset ID.\n      operationId: listDatasets\n      parameters:\n        - description: Index of the dataset from which you want to start paging\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of datsets to return. Maximum valid value is 25. If you specify a number greater than 25, the call returns 25 datasets.\n          in: query\n          name: count\n          schema:\n            default: \"25\"\n            type: string\n        - description: If true, returns all global datasets. Global datasets are public datasets that Salesforce provides.\n          in: query\n          name: global\n          schema:\n            default: false\n            type: boolean\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DatasetList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Datasets\n      tags:\n        - Language Datasets\n  /v2/language/datasets/upload:\n    post:\n      description: Creates a dataset, labels, and examples from the specified .csv, .tsv, or .json file. The call returns immediately and continues to upload data in the background.\n      operationId: uploadDatasetAsync\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Path to the .csv, .tsv, or .json file on the local drive (FilePart).\n                  type: string\n                name:\n                  description: Name of the dataset. Optional. If this parameter is omitted, the dataset name is derived from the file name.\n                  example: weather\n                  type: string\n                path:\n                  description: URL of the .csv, .tsv, or .json file.\n                  type: string\n                type:\n                  description: Type of dataset data.\n                  enum:\n                    - text-intent\n                    - text-sentiment\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload initiated\n      security:\n        - bearer_token: []\n      summary: Create a Dataset From a File Asynchronously\n      tags:\n        - Language Datasets\n  /v2/language/datasets/upload/sync:\n    post:\n      description: Creates a dataset, labels, and examples from the specified .csv, .tsv, or .json file. The call returns after the dataset is created and all of the data is uploaded.\n      operationId: uploadDatasetSync\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Path to the .csv, .tsv, or .json file on the local drive (FilePart).\n                  type: string\n                name:\n                  description: Name of the dataset. Optional. If this parameter is omitted, the dataset name is derived from the file name.\n                  example: weather\n                  type: string\n                path:\n                  description: URL of the .csv, .tsv, or .json file.\n                  type: string\n                type:\n                  description: Type of dataset data.\n                  enum:\n                    - text-intent\n                    - text-sentiment\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create a Dataset From a File Synchronously\n      tags:\n        - Language Datasets\n  \"/v2/language/datasets/{datasetId}\":\n    delete:\n      description: Deletes the specified dataset and associated labels and examples.\n      operationId: deleteDataset\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Delete a Dataset\n      tags:\n        - Language Datasets\n    get:\n      description: Returns a single dataset.\n      operationId: getDataset\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get a Dataset\n      tags:\n        - Language Datasets\n  \"/v2/language/datasets/{datasetId}/examples\":\n    get:\n      description: Returns all the examples for the specified dataset,\n      operationId: getExamples\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n        - description: Index of the example from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of examples to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n        - description: return examples that were created in the dataset as feedback\n          in: query\n          name: source\n          schema:\n            enum:\n              - all\n              - feedback\n              - upload\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ExampleList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Examples\n      tags:\n        - Language Examples\n  \"/v2/language/datasets/{datasetId}/models\":\n    get:\n      description: Returns all models for the specified dataset.\n      operationId: getTrainedModels\n      parameters:\n        - description: Index of the model from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of models to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ModelList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Models\n      tags:\n        - Language Models\n  \"/v2/language/datasets/{datasetId}/upload\":\n    put:\n      description: Adds examples from a .csv, .tsv, or .json file to a dataset.\n      operationId: updateDatasetAsync\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: \"Path to the .csv, .tsv, or .json file on a local drive. \"\n                  type: string\n                type:\n                  description: URL of the .csv, .tsv, or .json file.\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create Examples From a File\n      tags:\n        - Language Examples\n  \"/v2/language/deletion/{id}\":\n    get:\n      description: Returns the status of a language dataset or model deletion. When you delete a dataset or model, the deletion may not occur immediately. Use this call to find out when the deletion is complete.\n      operationId: get\n      parameters:\n        - description: Deletion Id\n          example: Z2JTFBF3A7XKIJC5QEJXMO4HSY\n          in: path\n          name: id\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: deletion status\n      security:\n        - bearer_token: []\n      summary: Get Deletion Status\n      tags:\n        - Language Datasets\n  /v2/language/examples:\n    get:\n      description: Returns all the examples for the specified label. Returns both uploaded examples and feedback examples.\n      operationId: getExamplesByLabel\n      parameters:\n        - description: Label Id\n          example: SomeLabelId\n          in: query\n          name: labelId\n          schema:\n            type: string\n        - description: Index of the example from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of examples to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ExampleList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Examples for Label\n      tags:\n        - Language Examples\n  /v2/language/feedback:\n    post:\n      description: Adds a feedback example to the dataset associated with the specified model.\n      operationId: provideFeedback\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                document:\n                  description: Intent or sentiment string to add to the dataset.\n                  type: string\n                expectedLabel:\n                  description: Correct label for the example. Must be a label that exists in the dataset.\n                  type: string\n                modelId:\n                  description: ID of the model that misclassified the image. The feedback example is added to the dataset associated with this model.\n                  type: string\n                name:\n                  description: Name of the example. Optional. Maximum length is 180 characters.\n                  example: feedback-2\n                  maxLength: 180\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Example\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create a Feedback Example\n      tags:\n        - Language Examples\n  /v2/language/intent:\n    post:\n      description: Returns an intent prediction for the given string.\n      operationId: intentMultipart\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/IntentPredictRequest\"\n          multipart/form-data:\n            schema:\n              $ref: \"#/components/schemas/IntentPredictRequest\"\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/IntentPredictResponse\"\n          description: Prediction Result\n        \"429\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/PredictionErrorResponse\"\n          description: Exceed usage limitation\n      security:\n        - bearer_token: []\n      summary: Prediction for Intent\n      tags:\n        - Language Prediction\n  \"/v2/language/models/{modelId}\":\n    delete:\n      description: Deletes the specified model.\n      operationId: deleteModel\n      parameters:\n        - description: Model Id\n          example: SomeModelId\n          in: path\n          name: modelId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"201\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: Deletion submitted\n      security:\n        - bearer_token: []\n      summary: Delete a Model\n      tags:\n        - Language Models\n    get:\n      description: Returns the metrics for a model\n      operationId: getTrainedModelMetrics\n      parameters:\n        - description: Model Id\n          example: SomeModelId\n          in: path\n          name: modelId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Metrics\"\n          description: Model Metrics\n      security:\n        - bearer_token: []\n      summary: Get Model Metrics\n      tags:\n        - Language Models\n  \"/v2/language/models/{modelId}/lc\":\n    get:\n      description: Returns the metrics for each epoch in a model.\n      operationId: getTrainedModelLearningCurve\n      parameters:\n        - description: Model Id\n          example: SomeModelId\n          in: path\n          name: modelId\n          required: true\n          schema:\n            type: string\n        - description: Index of the epoch from which you want to start paging\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of epoch to return. Maximum valid value is 25.\n          in: query\n          name: count\n          schema:\n            default: \"25\"\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LearningCurveList\"\n          description: Learning Curve\n      security:\n        - bearer_token: []\n      summary: Get Model Learning Curve\n      tags:\n        - Language Models\n  /v2/language/retrain:\n    post:\n      description: Retrains a dataset and updates a model. Use this API call when you want to update a model and keep the model ID instead of creating a new model.\n      operationId: retrain\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                algorithm:\n                  description: Algorithm used for train\n                  example: intent\n                  type: string\n                epochs:\n                  description: Number of training iterations for the neural network. Optional.\n                  example: 20\n                  format: int32\n                  maximum: 1000\n                  minimum: 1\n                  type: integer\n                learningRate:\n                  description: N/A for intent or sentiment models.\n                  example: 0.0001\n                  format: float\n                  type: number\n                modelId:\n                  description: ID of the model to be updated from the training.\n                  example: 7JXCXTRXTMNLJCEF2DR5CJ46QU\n                  type: string\n                trainParams:\n                  $ref: \"#/components/schemas/V2LanguageTrainParams\"\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Retrain a Dataset\n      tags:\n        - Language Training\n  /v2/language/sentiment:\n    post:\n      description: Returns a sentiment prediction for the given string.\n      operationId: sentimentMultipart\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/SentimentPredictRequest\"\n          multipart/form-data:\n            schema:\n              $ref: \"#/components/schemas/SentimentPredictRequest\"\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/SentimentPredictResponse\"\n          description: Prediction Result\n      security:\n        - bearer_token: []\n      summary: Prediction for Sentiment\n      tags:\n        - Language Prediction\n  /v2/language/train:\n    post:\n      description: Trains a dataset and creates a model.\n      operationId: train\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                algorithm:\n                  description: Algorithm used for train\n                  example: intent\n                  type: string\n                datasetId:\n                  description: ID of the dataset to train.\n                  example: 57\n                  format: int64\n                  type: integer\n                epochs:\n                  description: Number of training iterations for the neural network. Optional.\n                  example: 20\n                  format: int32\n                  maximum: 1000\n                  minimum: 1\n                  type: integer\n                learningRate:\n                  description: N/A for intent or sentiment models.\n                  format: double\n                  type: number\n                name:\n                  description: Name of the model. Maximum length is 180 characters.\n                  maxLength: 180\n                  type: string\n                trainParams:\n                  $ref: \"#/components/schemas/V2LanguageTrainParams\"\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Train a Dataset\n      tags:\n        - Language Training\n  \"/v2/language/train/{modelId}\":\n    get:\n      description: Returns the status of a model's training process. Use the progress field to determine how far the training has progressed. When training completes successfully, the status is SUCCEEDED and the progress is 1.\n      operationId: getTrainStatusAndProgress\n      parameters:\n        - description: Model Id\n          example: SomeModelId\n          in: path\n          name: modelId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Get Training Status\n      tags:\n        - Language Training\n  /v2/oauth2/token:\n    post:\n      description: Returns an OAuth access token or a refresh token. You must pass a valid access token in the header of each API call.\n      externalDocs:\n        description: authentication guid\n        url: https://metamind.readme.io/docs/generate-an-oauth-access-token\n      operationId: generateTokenV2\n      requestBody:\n        content:\n          application/x-www-form-urlencoded:\n            schema:\n              properties:\n                assertion:\n                  description: encrypted payload to identify yourself\n                  example: SOME_ASSERTION_STRING\n                  type: string\n                grant_type:\n                  description: specify the authentication method desired\n                  enum:\n                    - urn:ietf:params:oauth:grant-type:jwt-bearer\n                    - refresh_token\n                  example: urn:ietf:params:oauth:grant-type:jwt-bearer\n                  type: string\n                refresh_token:\n                  description: The refresh token you created previously.\n                  example: SomeRefreshToken\n                  type: string\n                scope:\n                  description: set to `offline` to generate a refresh token\n                  example: offline\n                  type: string\n                valid_for:\n                  default: 60\n                  description: Number of seconds until the access token expires. Default is 60 seconds. Maximum value is 30 days\n                  example: 120\n                  format: int32\n                  type: integer\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/GenerateAccessTokenResponse\"\n          description: access token result\n      summary: Generate an OAuth Token\n      tags:\n        - Authorization\n  \"/v2/oauth2/tokens/{token}\":\n    delete:\n      operationId: revokeRefreshTokenV2\n      parameters:\n        - description: the token to revoke\n          example: SOME_REFRESH_TOKEN\n          in: path\n          name: token\n          required: true\n          schema:\n            type: string\n      responses:\n        \"204\":\n          description: deleted, with no content returned\n        \"400\":\n          description: token cannot be removed\n        \"404\":\n          description: token not found\n      security:\n        - bearer_token: []\n      summary: Delete a Refresh Token\n      tags:\n        - Authorization\n  /v2/vision/bulkfeedback:\n    put:\n      description: Adds feedback examples to the dataset associated with the specified object detection model.\n      operationId: updateDatasetAsync_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Local .zip file to upload. The maximum .zip file size you can upload from a local drive is 50 MB.\n                  type: string\n                modelId:\n                  description: ID of the model that misclassified the images. The feedback examples are added to the dataset associated with this model.\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Update success\n      security:\n        - bearer_token: []\n      summary: Create Feedback Examples From a Zip File\n      tags:\n        - Vision Examples\n  /v2/vision/datasets:\n    get:\n      description: Returns a list of datasets and their labels that were created by the current user. The response is sorted by dataset ID.\n      operationId: listDatasets_1\n      parameters:\n        - description: Index of the dataset from which you want to start paging\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of datsets to return. Maximum valid value is 25. If you specify a number greater than 25, the call returns 25 datasets.\n          in: query\n          name: count\n          schema:\n            default: \"25\"\n            type: string\n        - description: If true, returns all global datasets. Global datasets are public datasets that Salesforce provides.\n          in: query\n          name: global\n          schema:\n            default: false\n            type: boolean\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DatasetList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Datasets\n      tags:\n        - Vision Datasets\n    post:\n      description: Creates a dataset and labels, if they're specified.\n      operationId: createDataset\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                labels:\n                  description: Optional comma-separated list of labels. If specified, creates the labels in the dataset. Maximum number of labels per dataset is 250.\n                  example: beach,mountain\n                  type: string\n                name:\n                  description: Name of the dataset. Maximum length is 180 characters.\n                  example: Beach and Mountain\n                  maxLength: 180\n                  type: string\n                type:\n                  description: Type of dataset data\n                  enum:\n                    - image\n                    - image-multi-label\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Creation success\n      security:\n        - bearer_token: []\n      summary: Create a Dataset\n      tags:\n        - Vision Datasets\n  /v2/vision/datasets/upload:\n    post:\n      description: Creates a dataset, labels, and examples from the specified .zip file. The call returns immediately and continues to upload the images in the background.\n      operationId: uploadDatasetAsync_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Path to the .zip file on the local drive (FilePart).\n                  type: string\n                name:\n                  description: Name of the dataset. Optional. If this parameter is omitted, the dataset name is derived from the .zip file name.\n                  example: mountainvsbeach\n                  type: string\n                path:\n                  description: URL of the .zip file.\n                  type: string\n                type:\n                  description: Type of dataset data.\n                  enum:\n                    - image\n                    - image-detection\n                    - image-multi-label\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload initiated\n      security:\n        - bearer_token: []\n      summary: Create a Dataset From a Zip File Asynchronously\n      tags:\n        - Vision Datasets\n  /v2/vision/datasets/upload/sync:\n    post:\n      description: Creates a dataset, labels, and examples from the specified .zip file. The call returns after the dataset is created and all of the images are uploaded.\n      operationId: uploadDatasetSync_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Path to the .zip file on the local drive (FilePart).\n                  type: string\n                name:\n                  description: Name of the dataset. Optional. If this parameter is omitted, the dataset name is derived from the .zip file name.\n                  example: mountainvsbeach\n                  type: string\n                path:\n                  description: URL of the .zip file.\n                  type: string\n                type:\n                  description: Type of dataset data.\n                  enum:\n                    - image\n                    - image-detection\n                    - image-multi-label\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create a Dataset From a Zip File Synchronously\n      tags:\n        - Vision Datasets\n  \"/v2/vision/datasets/{datasetId}\":\n    delete:\n      description: Deletes the specified dataset and associated labels and examples.\n      operationId: deleteDataset_1\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"201\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Delete a Dataset\n      tags:\n        - Vision Datasets\n    get:\n      description: Returns a single dataset.\n      operationId: getDataset_1\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get a Dataset\n      tags:\n        - Vision Datasets\n  \"/v2/vision/datasets/{datasetId}/examples\":\n    get:\n      description: Returns all the examples for the specified dataset. By default, returns examples created by uploading them from a .zip file.\n      operationId: getExamples_1\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n        - description: Index of the example from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of examples to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n        - description: return examples that were created in the dataset as feedback\n          in: query\n          name: source\n          schema:\n            enum:\n              - all\n              - feedback\n              - upload\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ExampleList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Examples\n      tags:\n        - Vision Examples\n    post:\n      description: Adds an example with the specified label to a dataset.\n      operationId: addExample\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Location of the local image file to upload.\n                  type: string\n                labelId:\n                  description: ID of the label to add to the example.\n                  example: 42\n                  format: int64\n                  type: integer\n                name:\n                  description: Name of the example. Maximum length is 180 characters.\n                  maxLength: 180\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Example\"\n          description: Example created\n      security:\n        - bearer_token: []\n      summary: Create an Example\n      tags:\n        - Vision Examples\n  \"/v2/vision/datasets/{datasetId}/models\":\n    get:\n      description: Returns all models for the specified dataset.\n      operationId: getTrainedModels_1\n      parameters:\n        - description: Index of the model from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of models to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ModelList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Models\n      tags:\n        - Vision Models\n  \"/v2/vision/datasets/{datasetId}/upload\":\n    put:\n      description: Adds examples from a .zip file to a dataset. You can use this call only with a dataset that was created from a .zip file.\n      operationId: updateDatasetAsync_2\n      parameters:\n        - description: Dataset Id\n          example: SomeDatasetId\n          in: path\n          name: datasetId\n          required: true\n          schema:\n            type: string\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Location of the local image file to upload.\n                  type: string\n                path:\n                  description: URL of the .zip file.\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Dataset\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create Examples From a Zip File\n      tags:\n        - Vision Examples\n  \"/v2/vision/deletion/{id}\":\n    get:\n      description: Returns the status of an image dataset or model deletion. When you delete a dataset or model, the deletion may not occur immediately. Use this call to find out when the deletion is complete.\n      operationId: get_1\n      parameters:\n        - description: Deletion Id\n          example: Z2JTFBF3A7XKIJC5QEJXMO4HSY\n          in: path\n          name: id\n          required: true\n          schema:\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: deletion status\n      security:\n        - bearer_token: []\n      summary: Get Deletion Status\n      tags:\n        - Vision Datasets\n  /v2/vision/detect:\n    post:\n      description: Returns labels, probabilities, and bounding box coordinates for items detected in the specified local image file.\n      operationId: detectMultipart\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/ObjectDetectionRequest\"\n          multipart/form-data:\n            schema:\n              $ref: \"#/components/schemas/ObjectDetectionRequest\"\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ObjectDetectionResponse\"\n          description: Detection Result\n      security:\n        - bearer_token: []\n      summary: Detection with Image File\n      tags:\n        - Vision Prediction\n  /v2/vision/examples:\n    get:\n      description: Returns all the examples for the specified label. Returns both uploaded examples and feedback examples.\n      operationId: getExamplesByLabel_1\n      parameters:\n        - description: Label Id\n          example: SomeLabelId\n          in: query\n          name: labelId\n          schema:\n            type: string\n        - description: Index of the example from which you want to start paging.\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of examples to return.\n          in: query\n          name: count\n          schema:\n            default: \"100\"\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ExampleList\"\n          description: Success\n      security:\n        - bearer_token: []\n      summary: Get All Examples for Label\n      tags:\n        - Vision Examples\n  /v2/vision/feedback:\n    post:\n      description: Adds a feedback example to the dataset associated with the specified model.\n      operationId: provideFeedback_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                data:\n                  description: Local image file to upload.\n                  type: string\n                expectedLabel:\n                  description: Correct label for the example. Must be a label that exists in the dataset.\n                  type: string\n                modelId:\n                  description: ID of the model that misclassified the image. The feedback example is added to the dataset associated with this model.\n                  type: string\n                name:\n                  description: Name of the example. Optional. Maximum length is 180 characters.\n                  example: feedback-1\n                  maxLength: 180\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Example\"\n          description: Upload success\n      security:\n        - bearer_token: []\n      summary: Create a Feedback Example\n      tags:\n        - Vision Examples\n  \"/v2/vision/models/{modelId}\":\n    delete:\n      description: Deletes the specified model.\n      operationId: deleteModel_1\n      parameters:\n        - in: path\n          name: modelId\n          required: true\n          schema:\n            description: Model Id\n            example: SomeModelId\n            type: string\n      responses:\n        \"201\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/DeletionResponse\"\n          description: Deletion submitted\n      security:\n        - bearer_token: []\n      summary: Delete a Model\n      tags:\n        - Vision Models\n    get:\n      description: Returns the metrics for a model\n      operationId: getTrainedModelMetrics_1\n      parameters:\n        - in: path\n          name: modelId\n          required: true\n          schema:\n            description: Model Id\n            example: SomeModelId\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/Metrics\"\n          description: Model Metrics\n      security:\n        - bearer_token: []\n      summary: Get Model Metrics\n      tags:\n        - Vision Models\n  \"/v2/vision/models/{modelId}/lc\":\n    get:\n      description: Returns the metrics for each epoch in a model.\n      operationId: getTrainedModelLearningCurve_1\n      parameters:\n        - in: path\n          name: modelId\n          required: true\n          schema:\n            description: Model Id\n            example: SomeModelId\n            type: string\n        - description: Index of the epoch from which you want to start paging\n          in: query\n          name: offset\n          schema:\n            default: \"0\"\n            type: string\n        - description: Number of epoch to return. Maximum valid value is 25.\n          in: query\n          name: count\n          schema:\n            default: \"25\"\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/LearningCurveList\"\n          description: Learning Curve\n      security:\n        - bearer_token: []\n      summary: Get Model Learning Curve\n      tags:\n        - Vision Models\n  /v2/vision/ocr:\n    post:\n      description: Returns a prediction from an OCR model for the specified image URL or local image file.\n      operationId: ocrMultipart\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                modelId:\n                  description: ID of the model that makes the prediction. Valid values are OCRModel and tabulatev2.\n                  example: WJH4YCA7YX4PCWVNCYNWYHBMY4\n                  type: string\n                sampleContent:\n                  description: Binary content of image file uploaded as multipart/form-data. Optional.\n                  format: binary\n                  type: string\n                sampleId:\n                  description: String that you can pass in to tag the prediction. Optional. Can be any value, and is returned in the response.\n                  type: string\n                sampleLocation:\n                  description: URL of the image file. Use this parameter when sending in a file from a web location. Optional.\n                  type: string\n                task:\n                  default: text\n                  description: \"Optional. Designates the type of data in the image. Default is text. Valid values: contact, table, and text.\"\n                  example: table\n                  type: string\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/OCRPredictResponse\"\n          description: OCR Result\n      security:\n        - bearer_token: []\n      summary: Detect Text\n      tags:\n        - Vision Prediction\n  /v2/vision/predict:\n    post:\n      description: Returns a prediction from an image or multi-label model for the specified image.\n      operationId: predictMultipart\n      requestBody:\n        content:\n          application/json:\n            schema:\n              $ref: \"#/components/schemas/ImageClassificationRequest\"\n          multipart/form-data:\n            schema:\n              $ref: \"#/components/schemas/ImageClassificationRequest\"\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/ImageClassificationResponse\"\n          description: Prediction Result\n      security:\n        - bearer_token: []\n      summary: Make Prediction\n      tags:\n        - Vision Prediction\n  /v2/vision/retrain:\n    post:\n      description: Retrains a dataset and updates a model. Use this API call when you want to update a model and keep the model ID instead of creating a new model.\n      operationId: retrain_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                algorithm:\n                  description: Specifies the algorithm used to train the dataset. Optional. Use this parameter only when training a dataset with a type of image-detection. Valid values are object-detection-v1 and retail-execution.\n                  example: object-detection\n                  type: string\n                epochs:\n                  description: Number of training iterations for the neural network. Optional.\n                  example: 20\n                  format: int32\n                  maximum: 1000\n                  minimum: 1\n                  type: integer\n                learningRate:\n                  description: Specifies how much the gradient affects the optimization of the model at each time step. Optional.\n                  example: 0.0001\n                  format: float\n                  type: number\n                modelId:\n                  description: ID of the model to be updated from the training.\n                  example: 7JXCXTRXTMNLJCEF2DR5CJ46QU\n                  type: string\n                trainParams:\n                  $ref: \"#/components/schemas/V2VisionTrainParams\"\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Retrain a Dataset\n      tags:\n        - Vision Training\n  /v2/vision/train:\n    post:\n      description: Trains a dataset and creates a model.\n      operationId: train_1\n      requestBody:\n        content:\n          multipart/form-data:\n            schema:\n              properties:\n                algorithm:\n                  description: Specifies the algorithm used to train the dataset. Optional. Use this parameter only when training a dataset with a type of image-detection. Valid values are object-detection-v1 and retail-execution.\n                  example: object-detection\n                  type: string\n                datasetId:\n                  description: ID of the dataset to train.\n                  example: 57\n                  format: int64\n                  type: integer\n                epochs:\n                  description: Number of training iterations for the neural network. Optional.\n                  example: 20\n                  format: int32\n                  maximum: 1000\n                  minimum: 1\n                  type: integer\n                learningRate:\n                  description: Specifies how much the gradient affects the optimization of the model at each time step. Optional.\n                  example: 0.0001\n                  format: double\n                  type: number\n                name:\n                  description: Name of the model. Maximum length is 180 characters.\n                  maxLength: 180\n                  type: string\n                trainParams:\n                  $ref: \"#/components/schemas/V2VisionTrainParams\"\n              type: object\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Train a Dataset\n      tags:\n        - Vision Training\n  \"/v2/vision/train/{modelId}\":\n    get:\n      description: Returns the status of a model's training process. Use the progress field to determine how far the training has progressed. When training completes successfully, the status is SUCCEEDED and the progress is 1.\n      operationId: getTrainStatusAndProgress_1\n      parameters:\n        - in: path\n          name: modelId\n          required: true\n          schema:\n            description: Model Id\n            example: SomeModelId\n            type: string\n      responses:\n        \"200\":\n          content:\n            application/json:\n              schema:\n                $ref: \"#/components/schemas/TrainResponse\"\n          description: Training Status\n      security:\n        - bearer_token: []\n      summary: Get Training Status\n      tags:\n        - Vision Training\ncomponents:\n  schemas:\n    ApiUsage:\n      properties:\n        endsAt:\n          format: date-time\n          title: Date and time that the plan calendar month ends. Always 12 am on the first day of the following month.\n          type: string\n        id:\n          example: \"489\"\n          title: Unique ID for the API usage plan month\n          type: string\n        licenseId:\n          example: kJCHtYDCSf\n          title: Unique ID of the API plan.\n          type: string\n        object:\n          example: apiusage\n          title: Object returned; in this case, apiusage.\n          type: string\n        organizationId:\n          example: \"108\"\n          title: Unique ID for the user making the API call\n          type: string\n        planData:\n          items:\n            $ref: \"#/components/schemas/PlanData\"\n          title: Plan data details\n          type: array\n        predictionsMax:\n          example: 1997\n          format: int64\n          title: Number of predictions left for the calendar month.\n          type: integer\n        predictionsUsed:\n          example: 3\n          format: int64\n          title: Number of predictions used in the calendar month.\n          type: integer\n        startsAt:\n          format: date-time\n          title: Date and time that the plan calendar month begins. Always the first of the month.\n          type: string\n      title: Api Usage\n      type: object\n    ApiUsageList:\n      properties:\n        data:\n          items:\n            $ref: \"#/components/schemas/ApiUsage\"\n          type: array\n        object:\n          example: list\n          title: Object returned; in this case, list.\n          type: string\n      title: Api Usage List\n      type: object\n    Attributes:\n      description: Contains additional attributes related to the task parameter. If the task parameter is table, the row and column IDs for the detected text are returned. If the task parameter is contact, the detected entity tags will be returned.\n      properties:\n        cellLocation:\n          $ref: \"#/components/schemas/CellLocation\"\n        language:\n          type: string\n        pageNumber:\n          type: string\n        tag:\n          type: string\n        value:\n          $ref: \"#/components/schemas/EntityObject\"\n      type: object\n    BoundingBox:\n      properties:\n        maxX:\n          description: X-coordinate of the left side of the bounding box. The origin of the coordinate system is the top-left of the image. Number of pixels from the left edge of the image.\n          format: int32\n          type: integer\n        maxY:\n          description: Y-coordinate of the top of the bounding box. Number of pixels from the top edge of the image.\n          format: int32\n          type: integer\n        minX:\n          description: X-coordinate of the right side of the bounding box. Number of pixels from the left edge of the image.\n          format: int32\n          type: integer\n        minY:\n          description: Y-coordinate of the bottom of the bounding box. Number of pixels from the top edge of the image.\n          format: int32\n          type: integer\n      type: object\n    CellLocation:\n      properties:\n        colIndex:\n          description: Index of the column that contains the detected text.\n          format: int32\n          type: integer\n        rowIndex:\n          description: Index of the row that contains the detected text.\n          format: int32\n          type: integer\n      type: object\n    Dataset:\n      properties:\n        available:\n          title: Specifies whether the dataset is ready to be trained.\n          type: boolean\n        createdAt:\n          description: Date and time that the dataset was created.\n          format: date-time\n          type: string\n        id:\n          example: 1000014\n          format: int64\n          title: Dataset ID.\n          type: integer\n        labelSummary:\n          $ref: \"#/components/schemas/LabelSummary\"\n        language:\n          description: Dataset language.\n          example: N/A\n          type: string\n        name:\n          example: weather report\n          title: Name of the dataset.\n          type: string\n        numOfDuplicates:\n          description: Number of duplicate images. This number includes duplicates in the .zip file from which the dataset was created plus the number of duplicate images from subsequent PUT calls to add images to the dataset.\n          format: int32\n          type: integer\n        object:\n          description: Object returned; in this case, dataset.\n          example: dataset\n          type: string\n        statusMsg:\n          example: SUCCEEDED\n          title: Status of the dataset creation and data upload.\n          type: string\n        totalExamples:\n          description: Total number of examples in the dataset.\n          example: 20\n          format: int32\n          type: integer\n        totalLabels:\n          description: Total number of labels in the dataset.\n          example: 2\n          format: int32\n          type: integer\n        type:\n          title: Type of dataset data.\n          type: string\n        updatedAt:\n          format: date-time\n          title: Date and time that the dataset was last updated.\n          type: string\n      required:\n        - id\n        - name\n      type: object\n    DatasetList:\n      properties:\n        data:\n          items:\n            $ref: \"#/components/schemas/Dataset\"\n          type: array\n        object:\n          example: list\n          title: Object returned; in this case, list.\n          type: string\n      type: object\n    DeletionResponse:\n      properties:\n        deletedObjectId:\n          example: \"1003360\"\n          title: ID of the object deleted. Depending on the object you delete, this contains the dataset ID or the model ID.\n          type: string\n        id:\n          example: Z2JTFBF3A7XKIJC5QEJXMO4HSY\n          title: ID of the deletion\n          type: string\n        message:\n          title: Additional information about the deletion. For example, a message is returned if the deletion fails.\n          type: string\n        object:\n          example: deletion\n          title: Object returned; in this case, deletion.\n          type: string\n        organizationId:\n          example: \"2\"\n          title: ID of the org to which the dataset or model being deleted belongs.\n          type: string\n        progress:\n          example: 1\n          format: double\n          title: How far the deletion has progressed. Values are between 0�1.\n          type: number\n        status:\n          enum:\n            - QUEUED\n            - RUNNING\n            - SUCCEEDED_WAITING_FOR_CACHE_REMOVAL\n            - SUCCEEDED\n            - KILLED\n            - FAILED\n            - RETRY\n          title: Status of the deletion.\n          type: string\n        type:\n          enum:\n            - DATASET\n            - MODEL\n          title: Object that's being deleted\n          type: string\n      type: object\n    DetectionResult:\n      description: label\n      properties:\n        boundingBox:\n          $ref: \"#/components/schemas/BoundingBox\"\n        label:\n          description: \"Probability lable for the input. \"\n          type: string\n        probability:\n          description: Probability value for the input. Values are between 0�1.\n          format: float\n          type: number\n      type: object\n    EntityObject:\n      properties:\n        boundingBox:\n          $ref: \"#/components/schemas/BoundingBox\"\n        entity:\n          type: string\n        text:\n          type: string\n      type: object\n    Example:\n      properties:\n        createdAt:\n          description: Date and time that the example was created.\n          format: date-time\n          type: string\n        id:\n          description: ID of the example.\n          example: 546\n          format: int64\n          type: integer\n        label:\n          $ref: \"#/components/schemas/Label\"\n        location:\n          description: URL of the image in the dataset. This is a temporary URL that expires in 30 minutes. This URL can be used to display images that were uploaded to a dataset in a UI.\n          example: https://K3A04Q79O5TBySIZSeMIj%2BC3zqi7rOmeK...\n          type: string\n        name:\n          description: Name of the example.\n          example: 659803277.jpg\n          type: string\n        object:\n          description: Object returned; in this case, example.\n          example: example\n          type: string\n      required:\n        - id\n        - name\n      type: object\n    ExampleList:\n      properties:\n        data:\n          items:\n            $ref: \"#/components/schemas/Example\"\n          type: array\n        object:\n          example: list\n          title: Object returned; in this case, list.\n          type: string\n      type: object\n    GenerateAccessTokenResponse:\n      properties:\n        access_token:\n          example: SPFPQ5IBLB6DPE6FKPWHMIWW4MCRICX4M4KQXFQMI6THZXIEZ6QGNWNOERD6S7655LJAFWTRIKC4KGYO5G3XROMEOTBSS53CFSB6GIA\n          title: Access token for authorization.\n          type: string\n        expires_in:\n          example: \"120\"\n          title: Number of seconds that the token will expire from the time it was generated.\n          type: string\n        refresh_token:\n          example: FL4GSVQS4W5CKSFRVZBLPIVZZJ2K4VIFPLGZ45SJGUQK4SS56IWPWACZ7V2B7OVLVKZCNK5JZSSW7CIHCNQJAO3TOUE3375108HHTLY\n          title: Refresh token that can be used to generate an access token. Only returned when you pass the scope=offline parameter to the endpoint.\n          type: string\n        token_type:\n          example: Bearer\n          title: Type of token returned. Always Bearer.\n          type: string\n      type: object\n    ImageClassificationRequest:\n      properties:\n        modelId:\n          description: ID of the model that makes the prediction.\n          example: WJH4YCA7YX4PCWVNCYNWYHBMY4\n          type: string\n        numResults:\n          description: Number of probabilities to return.\n          example: 3\n          format: int32\n          minimum: 1\n          type: integer\n        sampleBase64Content:\n          description: The image contained in a base64 string.\n          example: SomeBase64EncodedImage\n          type: string\n        sampleId:\n          description: String that you can pass in to tag the prediction. Optional. Can be any value, and is returned in the response.\n          type: string\n        sampleLocation:\n          description: URL of the image file.\n          type: string\n      required:\n        - modelId\n      type: object\n    ImageClassificationResponse:\n      properties:\n        object:\n          example: predictresponse\n          title: Object returned; in this case, predictresponse.\n          type: string\n        probabilities:\n          items:\n            $ref: \"#/components/schemas/LabelResult\"\n          type: array\n        sampleId:\n          description: Value passed in when the prediction call was made. Returned only if the sampleId request parameter is provided.\n          example: Sample1\n          type: string\n      type: object\n    IntentPredictRequest:\n      properties:\n        document:\n          description: Text for which you want to return an intent prediction.\n          example: I can't tell you how much fun it was\n          type: string\n        modelId:\n          description: ID of the model that makes the prediction. The model must have been created from a dataset with a type of text-sentiment.\n          example: WJH4YCA7YX4PCWVNCYNWYHBMY4\n          type: string\n        numResults:\n          description: \"Number of probabilities to return. \"\n          example: 3\n          format: int32\n          minimum: 1\n          type: integer\n        sampleId:\n          description: String that you can pass in to tag the prediction. Optional. Can be any value, and is returned in the response.\n          type: string\n      required:\n        - document\n        - modelId\n      type: object\n    IntentPredictResponse:\n      properties:\n        object:\n          example: predictresponse\n          title: Object returned; in this case, predictresponse.\n          type: string\n        probabilities:\n          items:\n            $ref: \"#/components/schemas/LabelResult\"\n          type: array\n        sampleId:\n          description: Value passed in when the prediction call was made. Returned only if the sampleId request parameter is provided.\n          example: Sample1\n          type: string\n      type: object\n    Label:\n      description: Contains information about the label with which the example is associated.\n      properties:\n        datasetId:\n          description: ID of the dataset that the label belongs to.\n          example: 57\n          format: int64\n          type: integer\n        id:\n          description: ID of the label.\n          example: 621\n          format: int64\n          type: integer\n        name:\n          description: Name of the label.\n          example: Mountain\n          type: string\n        numExamples:\n          description: Number of examples that have the label.\n          example: 40\n          format: int64\n          type: integer\n      required:\n        - datasetId\n        - name\n      type: object\n    LabelResult:\n      description: label\n      properties:\n        label:\n          description: \"Probability lable for the input. \"\n          type: string\n        probability:\n          description: Probability value for the input. Values are between 0�1.\n          format: float\n          type: number\n      type: object\n    LabelSummary:\n      description: Contains the labels array that contains all the labels for the dataset.\n      properties:\n        labels:\n          items:\n            $ref: \"#/components/schemas/Label\"\n          type: array\n      type: object\n    LearningCurve:\n      properties:\n        epoch:\n          description: Epoch to which the metrics correspond.\n          example: 1\n          type: object\n        epochResults:\n          description: Prediction results for the set of data used to test the model during training.\n          type: object\n        metricsData:\n          description: Model metrics values.\n          type: object\n        object:\n          description: Object returned; in this case, learningcurve.\n          example: learningcurve\n          type: string\n      type: object\n    LearningCurveList:\n      properties:\n        data:\n          items:\n            $ref: \"#/components/schemas/LearningCurve\"\n          type: array\n        object:\n          example: list\n          title: Object returned; in this case, list.\n          type: string\n      type: object\n    Metrics:\n      properties:\n        algorithm:\n          type: string\n        createdAt:\n          description: Date and time that the model was created.\n          format: date-time\n          type: string\n        id:\n          description: Model Id\n          type: string\n        language:\n          type: string\n        metricsData:\n          description: Model metrics values.\n          type: object\n        object:\n          type: string\n      type: object\n    Model:\n      properties:\n        algorithm:\n          description: Algorithm used to create the model. Returned only when the modelType is image-detection.\n          example: object-detection\n          type: string\n        createdAt:\n          description: Date and time that the model was created.\n          format: date-time\n          type: string\n        datasetId:\n          description: ID of the dataset trained to create the model.\n          example: 57\n          format: int64\n          type: integer\n        datasetVersionId:\n          description: Not available yet\n          example: 0\n          format: int64\n          type: integer\n        failureMsg:\n          description: Reason the dataset training failed. Returned only if the training status is FAILED.\n          example: To train a dataset and create a model, the dataset must contain at least 100 examples per label for test set\n          type: string\n        language:\n          description: Model language inherited from the dataset language. For image datasets, default is N/A. For text datasets, default is en_US.\n          example: en_US\n          type: string\n        modelId:\n          description: ID of the model. Contains letters and numbers.\n          example: 2KXJEOM3N562JBT4P7OX7VID2Q\n          type: string\n        modelType:\n          description: Type of data from which the model was created.\n          type: string\n        name:\n          description: Name of the model.\n          example: My Model - Version1\n          type: string\n        object:\n          description: Object returned; in this case, model.\n          example: model\n          type: string\n        progress:\n          description: How far the dataset training has progressed. Values are between 0�1.\n          type: number\n        status:\n          description: Status of the model.\n          enum:\n            - QUEUED\n            - RUNNING\n            - SUCCEEDED\n            - FAILED\n            - KILLED\n            - FAILED_WITH_RETRIES\n          type: string\n        updatedAt:\n          description: Date and time that the model was last updated.\n          format: date-time\n          type: string\n      required:\n        - datasetId\n        - datasetVersionId\n        - modelId\n        - name\n        - progress\n        - status\n      type: object\n    ModelList:\n      properties:\n        data:\n          items:\n            $ref: \"#/components/schemas/Model\"\n          type: array\n        object:\n          example: list\n          title: Object returned; in this case, list.\n          type: string\n      type: object\n    OCRPredictResponse:\n      properties:\n        object:\n          example: predictresponse\n          title: Object returned; in this case, predictresponse.\n          type: string\n        probabilities:\n          items:\n            $ref: \"#/components/schemas/OCRResult\"\n          type: array\n        sampleId:\n          description: Same value as request parameter. Returned only if the sampleId request parameter is provided.\n          example: Sample1\n          type: string\n        task:\n          description: Same value as request parameter. Returns text if the request parameter isn't supplied.\n          example: Task1\n          type: string\n      type: object\n    OCRResult:\n      description: Array of probabilities for the prediction.\n      properties:\n        attributes:\n          $ref: \"#/components/schemas/Attributes\"\n        boundingBox:\n          $ref: \"#/components/schemas/BoundingBox\"\n        label:\n          description: Content of the detected text.\n          type: string\n        probability:\n          description: Probability value for the input. Values are between 0�1.\n          format: float\n          type: number\n      type: object\n    ObjectDetectionRequest:\n      properties:\n        modelId:\n          description: ID of the model that makes the detection.\n          example: YCQ4ZACEPJFGXZNRA6ERF3GL5E\n          type: string\n        sampleBase64Content:\n          description: The image contained in a base64 string.\n          example: SomeBase64EncodedImage\n          type: string\n        sampleId:\n          description: String that you can pass in to tag the prediction. Optional. Can be any value, and is returned in the response.\n          type: string\n        sampleLocation:\n          description: URL of the image file.\n          type: string\n      required:\n        - modelId\n      type: object\n    ObjectDetectionResponse:\n      properties:\n        object:\n          example: predictresponse\n          title: Object returned; in this case, predictresponse.\n          type: string\n        probabilities:\n          items:\n            $ref: \"#/components/schemas/DetectionResult\"\n          type: array\n        sampleId:\n          description: Value passed in when the prediction call was made. Returned only if the sampleId request parameter is provided.\n          example: Sample1\n          type: string\n      type: object\n    PlanData:\n      properties:\n        amount:\n          example: 1\n          format: int32\n          title: Number of plans of the specified type.\n          type: integer\n        plan:\n          enum:\n            - STARTER\n            - SFDC_1M_EDITION\n            - BRONZE\n            - SILVER\n            - GOLD\n            - DATASET_DOWNLOAD\n          title: Type of plan based on the source.\n          type: string\n        source:\n          enum:\n            - SALESFORCE\n            - HEROKU\n            - SF_AUTO_PROVISION\n            - SF_AUTO_PROVISION_BOUND\n          title: Service that provisioned the plan.\n          type: string\n      title: Plan Data\n      type: object\n    PredictionErrorResponse:\n      properties:\n        message:\n          type: string\n        object:\n          type: string\n      type: object\n    SentimentPredictRequest:\n      properties:\n        document:\n          description: Text for which you want to return a sentiment prediction.\n          example: I can't tell you how much fun it was\n          type: string\n        modelId:\n          description: ID of the model that makes the prediction. The model must have been created from a dataset with a type of text-sentiment.\n          example: WJH4YCA7YX4PCWVNCYNWYHBMY4\n          type: string\n        numResults:\n          description: \"Number of probabilities to return. \"\n          example: 3\n          format: int32\n          minimum: 1\n          type: integer\n        sampleId:\n          description: String that you can pass in to tag the prediction. Optional. Can be any value, and is returned in the response.\n          type: string\n      required:\n        - document\n        - modelId\n      type: object\n    SentimentPredictResponse:\n      properties:\n        object:\n          example: predictresponse\n          title: Object returned; in this case, predictresponse.\n          type: string\n        probabilities:\n          items:\n            $ref: \"#/components/schemas/LabelResult\"\n          type: array\n        sampleId:\n          description: Value passed in when the prediction call was made. Returned only if the sampleId request parameter is provided.\n          example: Sample1\n          type: string\n      type: object\n    TrainResponse:\n      properties:\n        algorithm:\n          description: Algorithm used to create the model. Returned only when the modelType is image-detection.\n          example: object-detection\n          type: string\n        createdAt:\n          description: Date and time that the model was created.\n          format: date-time\n          type: string\n        datasetId:\n          description: ID of the dataset trained to create the model.\n          example: 57\n          format: int64\n          type: integer\n        datasetVersionId:\n          description: Not available yet\n          example: 0\n          format: int64\n          type: integer\n        epochs:\n          description: Number of epochs used during training.\n          example: 20\n          format: int32\n          type: integer\n        failureMsg:\n          description: Reason the dataset training failed. Returned only if the training status is FAILED.\n          example: To train a dataset and create a model, the dataset must contain at least 100 examples per label for test set\n          type: string\n        language:\n          description: Model language inherited from the dataset language. For image datasets, default is N/A. For text datasets, default is en_US.\n          example: en_US\n          type: string\n        learningRate:\n          description: Learning rate used during training.\n          example: 0.0001\n          format: double\n          type: number\n        modelId:\n          description: ID of the model. Contains letters and numbers.\n          example: 2KXJEOM3N562JBT4P7OX7VID2Q\n          type: string\n        modelType:\n          description: Type of data from which the model was created.\n          type: string\n        name:\n          description: Name of the model.\n          example: My Model - Version1\n          type: string\n        object:\n          description: Object returned; in this case, training.\n          example: training\n          type: string\n        progress:\n          description: How far the dataset training has progressed. Values are between 0�1.\n          example: 0.7\n          type: number\n        queuePosition:\n          description: Where the training job is in the queue. This field appears in the response only if the status is QUEUED.\n          example: 1\n          format: int32\n          type: integer\n        status:\n          description: Status of the model.\n          enum:\n            - QUEUED\n            - RUNNING\n            - SUCCEEDED\n            - FAILED\n            - KILLED\n            - FAILED_WITH_RETRIES\n          type: string\n        trainParams:\n          description: Training parameters passed into the request.\n          example: '{\"trainSplitRatio\":0.7}'\n          type: string\n        trainStats:\n          description: Returns null when you train a dataset. Training statistics are returned when the status is SUCCEEDED or FAILED.\n          type: string\n        updatedAt:\n          description: Date and time that the model was last updated.\n          format: date-time\n          type: string\n      required:\n        - datasetId\n        - datasetVersionId\n        - language\n        - modelId\n        - name\n        - progress\n        - status\n      type: object\n    V2LanguageTrainParams:\n      description: JSON that contains parameters that specify how the model is created\n      properties:\n        trainSplitRatio:\n          description: Lets you specify the ratio of data used to train the dataset and the data used to test the model.\n          example: 0.9\n          format: float\n          type: number\n        withFeedback:\n          description: Lets you specify that feedback examples are included in the data to be trained to create the model.\n          type: boolean\n        withGlobalDatasetId:\n          description: Lets you specify that a global dataset is used in addition to the specified dataset to create the model.\n          format: int64\n          type: integer\n      type: object\n    V2VisionTrainParams:\n      description: JSON that contains parameters that specify how the model is created\n      properties:\n        trainSplitRatio:\n          description: Lets you specify the ratio of data used to train the dataset and the data used to test the model.\n          example: 0.9\n          format: float\n          type: number\n        withFeedback:\n          description: Lets you specify that feedback examples are included in the data to be trained to create the model.\n          type: boolean\n        withGlobalDatasetId:\n          description: Lets you specify that a global dataset is used in addition to the specified dataset to create the model.\n          format: int64\n          type: integer\n      type: object\n  securitySchemes:\n    bearer_token:\n      scheme: bearer\n      type: http\n",
			"canonicalURL": "/github.com/APIs-guru/openapi-directory@47bf2b618e492e31bc62743e9f72c47cb8460229/-/blob/APIs/salesforce.local/einstein/2.0.1/openapi.yaml",
			"externalURLs": [
				{
					"url": "https://github.com/APIs-guru/openapi-directory/blob/47bf2b618e492e31bc62743e9f72c47cb8460229/APIs/salesforce.local/einstein/2.0.1/openapi.yaml",
					"serviceKind": "GITHUB"
				}
			]
		}
	}
}