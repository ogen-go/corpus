{
	"File": {
		"__typename": "FileMatch",
		"repository": {
			"name": "github.com/microsoft/CameraTraps"
		},
		"file": {
			"name": "openapi.yaml",
			"path": "api/synchronous/documentation/openapi.yaml",
			"content": "{\n    \"openapi\": \"3.0.1\",\n    \"info\": {\n        \"title\": \"AI for Earth Camera Trap Detection API\",\n        \"description\": \"API for detecting animals, people, and vehicles in camera trap images using the [MegaDetector](https://github.com/microsoft/CameraTraps/blob/master/megadetector.md) model.  This API is intended for real-time applications that process a small number of images at a time and require low latency; for batch processing applications, see the corresponding [batch processing API](https://github.com/microsoft/CameraTraps/tree/master/api/batch_processing).\",\n        \"version\": \"1.0\"\n    },\n    \"servers\": [{\n        \"url\": \"https://aiforearth.azure-api.net/api\"\n    }],\n    \"paths\": {\n        \"/v1/camera-trap/sync/detector_model_version\": {\n            \"get\": {\n                \"summary\": \"Returns the detector model's version.\",\n                \"description\": \"Returns a string indicating the version of the model currently used by\\nthis API.\\n\",\n                \"operationId\": \"get-detector_model_version\",\n                \"responses\": {\n                    \"200\": {\n                        \"description\": \"A string indicating the version of the model used.\",\n                        \"content\": {\n                            \"text/plain\": {\n                                \"schema\": {\n                                    \"$ref\": \"#/components/schemas/Detector_model_versionGet200TextPlainResponse\"\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        },\n        \"/v1/camera-trap/sync/detect\": {\n            \"post\": {\n                \"summary\": \"Processes the input image(s) using the detection model.\",\n                \"description\": \"Runs the detection model on up to eight images, optionally filtering detections based on a confidence threshold.\",\n                \"operationId\": \"post-detect\",\n                \"parameters\": [{\n                    \"name\": \"confidence\",\n                    \"in\": \"query\",\n                    \"description\": \"The confidence threshold above which a proposed bounding box is considered a detection. Set it to a low value, such as 0.05, if you would like to receive all candidate boxes.  When visualizing results using the `render` parameter, we recommend using a higher threshold, such as 0.8, for clearer visualizations.\",\n                    \"schema\": {\n                        \"type\": \"float\"\n                    }\n                }, {\n                    \"name\": \"render\",\n                    \"in\": \"query\",\n                    \"description\": \"If true, the endpoint will return all input images annotated with detection bounding boxes with confidence above the `confidence` threshold, in addition to the json result.\",\n                    \"schema\": {\n                        \"type\": \"boolean\",\n                        \"default\": false\n                    }\n                }],\n                \"requestBody\": {\n                    \"description\": \"Send up to 8 images to be processed as files in a multipart form. \\n\\n- The keys (`image_name` in the following example) in the files dictionary should be unique identifiers of the images, as the returned result will also be keyed by these.\\n\\n- Make sure to set the content media type correctly for each file, as only files of the accepted types will be processed. \\n\\n- The accepted image types are `image/jpeg`, `image/png`, `application/octet-stream`. Please send jpeg images of usual camera trap images size (500KB - 4MB).\\n\\nFor example, in Python:\\n```\\n  import requests\\n  import os\\n\\n  num_images_to_upload = 3\\n  params = {\\n      'confidence': 0.8,\\n      'render': True\\n  }\\n  \\n  files = {}\\n  num_images = 0\\n  for i, image_name in enumerate(sorted(os.listdir(sample_input_dir))):\\n      if not image_name.lower().endswith('.jpg'):\\n          continue\\n      \\n      if num_images \u003e= num_images_to_upload:\\n          break\\n      else:\\n          num_images += 1\\n      \\n      img_path = os.path.join(sample_input_dir, image_name)\\n      files[image_name] = (image_name, open(img_path, 'rb'), 'image/jpeg')\\n      \\n  r = requests.post(base_url + 'detect', params=params, files=files)\\n```\\n\",\n                    \"content\": {\n                        \"multipart/form-data\": {}\n                    }\n                },\n                \"responses\": {\n                    \"200\": {\n                        \"description\": \"Images are successfully processed. The detection bounding boxes, their confidences and categories will be returned in .json format.  If the `render` parameter was `true`, annotated images will be returned as well. Since multiple objects of different types may be returned, the response is encoded using `requests_toolbelt.multipart.encoder.MultipartEncoder`.\\n\\nA result is a json-encoded dictionary, where the keys are the unique image identifier that you specified for each image in the request body.  Each value is an array containing the detections above `confidence` that were found on that image. The array is empty if no animals/people/vehicles are detected above the confidence threshold. Each detection is an array, formatted as `[ymin, xmin, ymax, xmax, confidence, category]`, where the first four floats are the _relative_ coordinates of the bounding box.  `category` is one of 1 (animal), 2 (person), or 3 (vehicle).\\n\\n\\nHere is an example of how you can parse the result in Python:\\n\\n```\\nimport os\\nimport json\\nfrom requests_toolbelt.multipart import decoder\\nfrom PIL import Image\\n\\nresults = decoder.MultipartDecoder.from_response(r)\\n\\ntext_results = {}\\nimages = {}\\nfor part in results.parts:\\n    # part is a BodyPart object with b'Content-Type', and b'Content-Disposition', the later includes 'name' and 'filename' info\\n    headers = {}\\n    for k, v in part.headers.items():\\n        headers[k.decode(part.encoding)] = v.decode(part.encoding)\\n    if headers.get('Content-Type', None) == 'image/jpeg':\\n        c = headers.get('Content-Disposition')\\n        image_name = c.split('name=\\\"')[1].split('\\\"')[0]  # this is an HTTP string; you can parse it more elegantly using a library\\n        image = Image.open(io.BytesIO(part.content))\\n        \\n        images[image_name] = image\\n    \\n    elif headers.get('Content-Type', None) == 'application/json':\\n        text_result = json.loads(part.content.decode())\\n        \\nfor img_name, img in sorted(images.items()):\\n  img.save(img_name + '.jpg')\\n```\\n\\n`text_result` looks like this:\\n\\n```\\n{\\n  'S1_D04_R6_PICT0022.JPG': [[0.011515299789607525,\\n   0.11399328708648682,\\n   0.9100480079650879,\\n   1.0,\\n   0.9953194260597229, 1]],\\n 'S1_D04_R6_PICT0128.JPG': [[0.5885017514228821,\\n   0.019416160881519318,\\n   0.6662894487380981,\\n   0.16861802339553833,\\n   0.8873217105865479, 2]],\\n 'S1_D04_R6_PICT0129.JPG': []\\n}\\n```\\n\",\n                        \"content\": {\n                            \"multipart/form-data\": {}\n                        }\n                    },\n                    \"400\": {\n                        \"description\": \"No image(s) of accepted types (image/jpeg, image/png,\\napplication/octet-stream) received, or the `confidence` parameter is\\nnot a float between 0 and 1.\\n\"\n                    },\n                    \"413\": {\n                        \"description\": \"More than 8 images are sent, or the total size of uploaded content is too\\nbig.\\n\"\n                    },\n                    \"500\": {\n                        \"description\": \"Error occurred reading the images, performing detection on the\\nimages, consolidating the results or drawing annotations (if\\nrequested). See the error message to diagnose the issue.\\n\"\n                    }\n                }\n            }\n        }\n    },\n    \"components\": {\n        \"schemas\": {\n            \"body\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"image_id_1\": {\n                        \"type\": \"string\",\n                        \"format\": \"binary\"\n                    }\n                }\n            },\n            \"Detector_model_versionGet200TextPlainResponse\": {\n                \"type\": \"string\",\n                \"example\": \"models/object_detection/faster_rcnn_inception_resnet_v2_atrous/megadetector\"\n            }\n        },\n        \"securitySchemes\": {\n            \"apiKeyHeader\": {\n                \"type\": \"apiKey\",\n                \"name\": \"Ocp-Apim-Subscription-Key\",\n                \"in\": \"header\"\n            },\n            \"apiKeyQuery\": {\n                \"type\": \"apiKey\",\n                \"name\": \"subscription-key\",\n                \"in\": \"query\"\n            }\n        }\n    },\n    \"security\": [{\n        \"apiKeyHeader\": []\n    }, {\n        \"apiKeyQuery\": []\n    }]\n}\n"
		}
	},
	"Error": "parse: paths: /v1/camera-trap/sync/detect: post: operation \"post-detect\": parameters: parse parameter \"confidence\": schema: parse schema: unexpected schema type: \"float\""
}